{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000  221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000  538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000  180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000  604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000  510000.0         3       2.00   \n",
       "...           ...              ...       ...       ...        ...   \n",
       "21608   263000018  20140521T000000  360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000  400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "0             1180      5650     1.0           0     0  ...      7   \n",
       "1             2570      7242     2.0           0     0  ...      7   \n",
       "2              770     10000     1.0           0     0  ...      6   \n",
       "3             1960      5000     1.0           0     0  ...      7   \n",
       "4             1680      8080     1.0           0     0  ...      8   \n",
       "...            ...       ...     ...         ...   ...  ...    ...   \n",
       "21608         1530      1131     3.0           0     0  ...      8   \n",
       "21609         2310      5813     2.0           0     0  ...      8   \n",
       "21610         1020      1350     2.0           0     0  ...      7   \n",
       "21611         1600      2388     2.0           0     0  ...      8   \n",
       "21612         1020      1076     2.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "...        ...            ...         ...  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_casas = pd.read_csv('house_prices.csv')\n",
    "base_casas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_casas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.400881e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.671272e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_casas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_casas.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '20141013T000000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbase_casas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '20141013T000000'"
     ]
    }
   ],
   "source": [
    "base_casas.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '20141013T000000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m figura \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mbase_casas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m);\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\pacie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '20141013T000000'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figura = plt.figure(figsize=(20,20))\n",
    "sns.heatmap(base_casas.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_casas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.00000e+00,  1.00000e+00,  1.18000e+03, ...,  9.81780e+04,\n",
       "         4.75112e+01, -1.22257e+02],\n",
       "       [ 3.00000e+00,  2.25000e+00,  2.57000e+03, ...,  9.81250e+04,\n",
       "         4.77210e+01, -1.22319e+02],\n",
       "       [ 2.00000e+00,  1.00000e+00,  7.70000e+02, ...,  9.80280e+04,\n",
       "         4.77379e+01, -1.22233e+02],\n",
       "       ...,\n",
       "       [ 2.00000e+00,  7.50000e-01,  1.02000e+03, ...,  9.81440e+04,\n",
       "         4.75944e+01, -1.22299e+02],\n",
       "       [ 3.00000e+00,  2.50000e+00,  1.60000e+03, ...,  9.80270e+04,\n",
       "         4.75345e+01, -1.22069e+02],\n",
       "       [ 2.00000e+00,  7.50000e-01,  1.02000e+03, ...,  9.81440e+04,\n",
       "         4.75941e+01, -1.22299e+02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = base_casas.iloc[:, 3:19].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.00000e+00,  1.00000e+00,  1.18000e+03,  5.65000e+03,\n",
       "        1.00000e+00,  0.00000e+00,  0.00000e+00,  3.00000e+00,\n",
       "        7.00000e+00,  1.18000e+03,  0.00000e+00,  1.95500e+03,\n",
       "        0.00000e+00,  9.81780e+04,  4.75112e+01, -1.22257e+02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221900., 538000., 180000., ..., 402101., 400000., 325000.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = base_casas.iloc[:, 2].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15129, 16), (6484, 16))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treinamento.shape, X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15129,), (6484,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-122.514, 1651359.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treinamento.min(), X_treinamento.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\pacie\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = 'pb-aws-teste2-s3'\n",
    "subpasta_modelo = 'modelos/house-prices/linear-learner'\n",
    "subpasta_dataset = 'datasets/house-prices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::992382374294:role/service-role/AmazonSageMaker-ExecutionRole-20240615T181656\n"
     ]
    }
   ],
   "source": [
    "role = 'arn:aws:iam::992382374294:role/service-role/AmazonSageMaker-ExecutionRole-20240615T181656'\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import sagemaker.amazon.common as smac # sagemaker commom library\n",
    "\n",
    "buffer = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buffer, X_treinamento, y_treinamento)\n",
    "buffer.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "key = 'houses-train-data'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(subpasta_dataset, 'train', key).replace('\\\\', '/')).upload_fileobj(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/house-prices\\\\train\\\\houses-train-data'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(subpasta_dataset, 'train', key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localização da base de treinamento: s3://pb-aws-teste2-s3/datasets/house-prices/train/houses-train-data\n"
     ]
    }
   ],
   "source": [
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, subpasta_dataset, key)\n",
    "print('Localização da base de treinamento: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final será salvo em: s3://pb-aws-teste2-s3/modelos/house-prices/linear-learner/output\n"
     ]
    }
   ],
   "source": [
    "output_location = 's3://{}/{}/output'.format(bucket, subpasta_modelo)\n",
    "print('Modelo final será salvo em: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação e treinamento do Linear Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ecr-sa-east-1.html\n",
    "container = sagemaker.image_uris.retrieve(framework = 'linear-learner', region=boto3.Session().region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aws.amazon.com/ec2/instance-types/\n",
    "# https://docs.aws.amazon.com/pt_br/AWSEC2/latest/UserGuide/instance-types.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
    "# https://aws.amazon.com/pt/about-aws/whats-new/2019/08/amazon-sagemaker-launches-managed-spot-training-saving-machine-learning-training-costs/\n",
    "linear = sagemaker.estimator.Estimator(image_uri = container,\n",
    "                                       role = role,\n",
    "                                       instance_count = 1,\n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = session,\n",
    "                                       use_stop_instances = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ll_hyperparameters.html\n",
    "linear.set_hyperparameters(feature_dim = 16,\n",
    "                           predictor_type = 'regressor',\n",
    "                           num_models = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: linear-learner-2024-06-16-15-16-38-002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-16 15:16:40 Starting - Starting the training job...\n",
      "2024-06-16 15:17:06 Starting - Preparing the instances for training......\n",
      "2024-06-16 15:17:55 Downloading - Downloading input data...\n",
      "2024-06-16 15:18:20 Downloading - Downloading the training image......\n",
      "2024-06-16 15:19:41 Training - Training image download completed. Training in progress..Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "[06/16/2024 15:20:02 INFO 139954502117184] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\n",
      "[06/16/2024 15:20:02 INFO 139954502117184] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '16', 'num_models': '16', 'predictor_type': 'regressor'}\n",
      "[06/16/2024 15:20:02 INFO 139954502117184] Final configuration: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': '16', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '16', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if cons['type'] is 'ineq':\n",
      "/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:743: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if len(self.X_min) is not 0:\n",
      "[06/16/2024 15:20:06 WARNING 139954502117184] Loggers have already been setup.\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Final configuration: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': '16', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '16', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\n",
      "[06/16/2024 15:20:06 WARNING 139954502117184] Loggers have already been setup.\n",
      "Process 7 is a worker.\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Using default worker.\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Checkpoint loading and saving are disabled.\n",
      "[2024-06-16 15:20:06.143] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 17, \"num_examples\": 1, \"num_bytes\": 108000}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Create Store: local\n",
      "[2024-06-16 15:20:06.233] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 89, \"num_examples\": 11, \"num_bytes\": 1188000}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f49220ed520>\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Scaling model computed with parameters:\n",
      " {'stdev_label': \n",
      "[369774.16]\n",
      "<NDArray 1 @cpu(0)>, 'stdev_weight': \n",
      "[9.0904909e-01 7.6650435e-01 9.2861407e+02 4.0837086e+04 5.4343110e-01\n",
      " 9.0577520e-02 7.7630913e-01 6.5075797e-01 1.1828393e+00 8.3386279e+02\n",
      " 4.4298438e+02 2.9392477e+01 3.9952466e+02 5.3384716e+01 1.3865680e-01\n",
      " 1.4118944e-01]\n",
      "<NDArray 16 @cpu(0)>, 'mean_label': \n",
      "[541735.8]\n",
      "<NDArray 1 @cpu(0)>, 'mean_weight': \n",
      "[ 3.36790943e+00  2.11359119e+00  2.07932544e+03  1.52805723e+04\n",
      "  1.49909091e+00  8.27272795e-03  2.41545469e-01  3.40481782e+00\n",
      "  7.65427351e+00  1.78847156e+03  2.90853577e+02  1.97101721e+03\n",
      "  8.34619217e+01  9.80772266e+04  4.75593491e+01 -1.22213646e+02]\n",
      "<NDArray 16 @cpu(0)>}\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] nvidia-smi: took 0.034 seconds to run.\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] nvidia-smi identified 0 GPUs.\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Number of GPUs being used: 0\n",
      "#metrics {\"StartTime\": 1718551206.303575, \"EndTime\": 1718551206.303614, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "[2024-06-16 15:20:06.474] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 170, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551206.4748194, \"EndTime\": 1718551206.4748714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.6305879252115886, \"count\": 1, \"min\": 0.6305879252115886, \"max\": 0.6305879252115886}}}\n",
      "#metrics {\"StartTime\": 1718551206.4749532, \"EndTime\": 1718551206.4749672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.9151852884928385, \"count\": 1, \"min\": 0.9151852884928385, \"max\": 0.9151852884928385}}}\n",
      "#metrics {\"StartTime\": 1718551206.4750059, \"EndTime\": 1718551206.4750152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7541974283854167, \"count\": 1, \"min\": 0.7541974283854167, \"max\": 0.7541974283854167}}}\n",
      "#metrics {\"StartTime\": 1718551206.4750443, \"EndTime\": 1718551206.475052, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.8546111999511719, \"count\": 1, \"min\": 0.8546111999511719, \"max\": 0.8546111999511719}}}\n",
      "#metrics {\"StartTime\": 1718551206.475083, \"EndTime\": 1718551206.4750907, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7214569641113281, \"count\": 1, \"min\": 0.7214569641113281, \"max\": 0.7214569641113281}}}\n",
      "#metrics {\"StartTime\": 1718551206.4751225, \"EndTime\": 1718551206.4751306, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7483868733723958, \"count\": 1, \"min\": 0.7483868733723958, \"max\": 0.7483868733723958}}}\n",
      "#metrics {\"StartTime\": 1718551206.475163, \"EndTime\": 1718551206.4751706, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7357669993082683, \"count\": 1, \"min\": 0.7357669993082683, \"max\": 0.7357669993082683}}}\n",
      "#metrics {\"StartTime\": 1718551206.4752011, \"EndTime\": 1718551206.4752088, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.6984275695800781, \"count\": 1, \"min\": 0.6984275695800781, \"max\": 0.6984275695800781}}}\n",
      "#metrics {\"StartTime\": 1718551206.4752347, \"EndTime\": 1718551206.4752417, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7516035949707032, \"count\": 1, \"min\": 0.7516035949707032, \"max\": 0.7516035949707032}}}\n",
      "#metrics {\"StartTime\": 1718551206.4752712, \"EndTime\": 1718551206.4752789, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7149037272135417, \"count\": 1, \"min\": 0.7149037272135417, \"max\": 0.7149037272135417}}}\n",
      "#metrics {\"StartTime\": 1718551206.4753098, \"EndTime\": 1718551206.4753175, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7451605916341146, \"count\": 1, \"min\": 0.7451605916341146, \"max\": 0.7451605916341146}}}\n",
      "#metrics {\"StartTime\": 1718551206.475346, \"EndTime\": 1718551206.475353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.6156784464518229, \"count\": 1, \"min\": 0.6156784464518229, \"max\": 0.6156784464518229}}}\n",
      "#metrics {\"StartTime\": 1718551206.475375, \"EndTime\": 1718551206.4753811, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7395220784505209, \"count\": 1, \"min\": 0.7395220784505209, \"max\": 0.7395220784505209}}}\n",
      "#metrics {\"StartTime\": 1718551206.4754024, \"EndTime\": 1718551206.4754086, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7427804606119792, \"count\": 1, \"min\": 0.7427804606119792, \"max\": 0.7427804606119792}}}\n",
      "#metrics {\"StartTime\": 1718551206.4754303, \"EndTime\": 1718551206.4754364, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7310327941894531, \"count\": 1, \"min\": 0.7310327941894531, \"max\": 0.7310327941894531}}}\n",
      "#metrics {\"StartTime\": 1718551206.4754574, \"EndTime\": 1718551206.4754639, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.7126970784505209, \"count\": 1, \"min\": 0.7126970784505209, \"max\": 0.7126970784505209}}}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #quality_metric: host=algo-1, epoch=0, train mse_objective <loss>=0.6305879252115886\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=mse_objective, value=0.6156784464518229\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Epoch 0: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Saving model for epoch: 0\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Saved checkpoint to \"/tmp/tmp6j48x05t/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\n",
      "#metrics {\"StartTime\": 1718551206.3039174, \"EndTime\": 1718551206.4856167, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 27129.0, \"count\": 1, \"min\": 27129, \"max\": 27129}, \"Total Batches Seen\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=83202.92399375344 records/second\n",
      "[2024-06-16 15:20:06.651] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 165, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551206.6512437, \"EndTime\": 1718551206.6513147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.4012074666341146, \"count\": 1, \"min\": 0.4012074666341146, \"max\": 0.4012074666341146}}}\n",
      "#metrics {\"StartTime\": 1718551206.6514223, \"EndTime\": 1718551206.6514437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.5315248026529948, \"count\": 1, \"min\": 0.5315248026529948, \"max\": 0.5315248026529948}}}\n",
      "#metrics {\"StartTime\": 1718551206.6515074, \"EndTime\": 1718551206.6515245, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.4534969604492187, \"count\": 1, \"min\": 0.4534969604492187, \"max\": 0.4534969604492187}}}\n",
      "#metrics {\"StartTime\": 1718551206.651584, \"EndTime\": 1718551206.6516023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.5048385803222656, \"count\": 1, \"min\": 0.5048385803222656, \"max\": 0.5048385803222656}}}\n",
      "#metrics {\"StartTime\": 1718551206.651666, \"EndTime\": 1718551206.651684, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3866945536295573, \"count\": 1, \"min\": 0.3866945536295573, \"max\": 0.3866945536295573}}}\n",
      "#metrics {\"StartTime\": 1718551206.6517458, \"EndTime\": 1718551206.6517632, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.37183333231608073, \"count\": 1, \"min\": 0.37183333231608073, \"max\": 0.37183333231608073}}}\n",
      "#metrics {\"StartTime\": 1718551206.651814, \"EndTime\": 1718551206.6518295, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3752923177083333, \"count\": 1, \"min\": 0.3752923177083333, \"max\": 0.3752923177083333}}}\n",
      "#metrics {\"StartTime\": 1718551206.651882, \"EndTime\": 1718551206.6518989, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3848090047200521, \"count\": 1, \"min\": 0.3848090047200521, \"max\": 0.3848090047200521}}}\n",
      "#metrics {\"StartTime\": 1718551206.6519618, \"EndTime\": 1718551206.6519785, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.4536178202311198, \"count\": 1, \"min\": 0.4536178202311198, \"max\": 0.4536178202311198}}}\n",
      "#metrics {\"StartTime\": 1718551206.652031, \"EndTime\": 1718551206.6520483, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.43946819458007813, \"count\": 1, \"min\": 0.43946819458007813, \"max\": 0.43946819458007813}}}\n",
      "#metrics {\"StartTime\": 1718551206.6521006, \"EndTime\": 1718551206.6521173, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.46353741251627606, \"count\": 1, \"min\": 0.46353741251627606, \"max\": 0.46353741251627606}}}\n",
      "#metrics {\"StartTime\": 1718551206.6521773, \"EndTime\": 1718551206.652194, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.38018133341471355, \"count\": 1, \"min\": 0.38018133341471355, \"max\": 0.38018133341471355}}}\n",
      "#metrics {\"StartTime\": 1718551206.6522565, \"EndTime\": 1718551206.6522732, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3696415863037109, \"count\": 1, \"min\": 0.3696415863037109, \"max\": 0.3696415863037109}}}\n",
      "#metrics {\"StartTime\": 1718551206.6523387, \"EndTime\": 1718551206.652356, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3751913299560547, \"count\": 1, \"min\": 0.3751913299560547, \"max\": 0.3751913299560547}}}\n",
      "#metrics {\"StartTime\": 1718551206.65241, \"EndTime\": 1718551206.652427, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.374212841796875, \"count\": 1, \"min\": 0.374212841796875, \"max\": 0.374212841796875}}}\n",
      "#metrics {\"StartTime\": 1718551206.6524792, \"EndTime\": 1718551206.6524956, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3810470408121745, \"count\": 1, \"min\": 0.3810470408121745, \"max\": 0.3810470408121745}}}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #quality_metric: host=algo-1, epoch=1, train mse_objective <loss>=0.4012074666341146\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=mse_objective, value=0.3696415863037109\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Epoch 1: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Saving model for epoch: 1\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Saved checkpoint to \"/tmp/tmpb1_inea0/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\n",
      "#metrics {\"StartTime\": 1718551206.4859264, \"EndTime\": 1718551206.6608658, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 42258.0, \"count\": 1, \"min\": 42258, \"max\": 42258}, \"Total Batches Seen\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=86417.66225333315 records/second\n",
      "[2024-06-16 15:20:06.844] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 182, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551206.8441474, \"EndTime\": 1718551206.844212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3461783782958984, \"count\": 1, \"min\": 0.3461783782958984, \"max\": 0.3461783782958984}}}\n",
      "#metrics {\"StartTime\": 1718551206.8443015, \"EndTime\": 1718551206.8443213, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.4020977193196615, \"count\": 1, \"min\": 0.4020977193196615, \"max\": 0.4020977193196615}}}\n",
      "#metrics {\"StartTime\": 1718551206.8443854, \"EndTime\": 1718551206.844404, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3564720876057943, \"count\": 1, \"min\": 0.3564720876057943, \"max\": 0.3564720876057943}}}\n",
      "#metrics {\"StartTime\": 1718551206.844455, \"EndTime\": 1718551206.8444715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3859850362141927, \"count\": 1, \"min\": 0.3859850362141927, \"max\": 0.3859850362141927}}}\n",
      "#metrics {\"StartTime\": 1718551206.8445253, \"EndTime\": 1718551206.8445408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31839737345377606, \"count\": 1, \"min\": 0.31839737345377606, \"max\": 0.31839737345377606}}}\n",
      "#metrics {\"StartTime\": 1718551206.844594, \"EndTime\": 1718551206.8446097, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3127478098551432, \"count\": 1, \"min\": 0.3127478098551432, \"max\": 0.3127478098551432}}}\n",
      "#metrics {\"StartTime\": 1718551206.8446908, \"EndTime\": 1718551206.8447075, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3158734690348307, \"count\": 1, \"min\": 0.3158734690348307, \"max\": 0.3158734690348307}}}\n",
      "#metrics {\"StartTime\": 1718551206.8447676, \"EndTime\": 1718551206.8447845, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3182196573893229, \"count\": 1, \"min\": 0.3182196573893229, \"max\": 0.3182196573893229}}}\n",
      "#metrics {\"StartTime\": 1718551206.8448348, \"EndTime\": 1718551206.8448513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.36467114969889325, \"count\": 1, \"min\": 0.36467114969889325, \"max\": 0.36467114969889325}}}\n",
      "#metrics {\"StartTime\": 1718551206.8449066, \"EndTime\": 1718551206.8449214, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3608036682128906, \"count\": 1, \"min\": 0.3608036682128906, \"max\": 0.3608036682128906}}}\n",
      "#metrics {\"StartTime\": 1718551206.8449783, \"EndTime\": 1718551206.844994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3787685099283854, \"count\": 1, \"min\": 0.3787685099283854, \"max\": 0.3787685099283854}}}\n",
      "#metrics {\"StartTime\": 1718551206.8450522, \"EndTime\": 1718551206.8450687, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3291859771728516, \"count\": 1, \"min\": 0.3291859771728516, \"max\": 0.3291859771728516}}}\n",
      "#metrics {\"StartTime\": 1718551206.8451173, \"EndTime\": 1718551206.8451326, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3098700368245443, \"count\": 1, \"min\": 0.3098700368245443, \"max\": 0.3098700368245443}}}\n",
      "#metrics {\"StartTime\": 1718551206.8451831, \"EndTime\": 1718551206.8451986, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31454075724283853, \"count\": 1, \"min\": 0.31454075724283853, \"max\": 0.31454075724283853}}}\n",
      "#metrics {\"StartTime\": 1718551206.8452551, \"EndTime\": 1718551206.8452716, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3157285837809245, \"count\": 1, \"min\": 0.3157285837809245, \"max\": 0.3157285837809245}}}\n",
      "#metrics {\"StartTime\": 1718551206.8453295, \"EndTime\": 1718551206.8453448, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3174463857014974, \"count\": 1, \"min\": 0.3174463857014974, \"max\": 0.3174463857014974}}}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #quality_metric: host=algo-1, epoch=2, train mse_objective <loss>=0.3461783782958984\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=mse_objective, value=0.3098700368245443\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Epoch 2: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Saving model for epoch: 2\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] Saved checkpoint to \"/tmp/tmplwm2yqwf/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #progress_metric: host=algo-1, completed 20.0 % of epochs\n",
      "#metrics {\"StartTime\": 1718551206.6612258, \"EndTime\": 1718551206.853803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 57387.0, \"count\": 1, \"min\": 57387, \"max\": 57387}, \"Total Batches Seen\": {\"sum\": 60.0, \"count\": 1, \"min\": 60, \"max\": 60}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:06 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=78500.3800541351 records/second\n",
      "[2024-06-16 15:20:07.020] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 165, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551207.0201719, \"EndTime\": 1718551207.020244, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3204693450927734, \"count\": 1, \"min\": 0.3204693450927734, \"max\": 0.3204693450927734}}}\n",
      "#metrics {\"StartTime\": 1718551207.020385, \"EndTime\": 1718551207.0204067, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.35134868469238284, \"count\": 1, \"min\": 0.35134868469238284, \"max\": 0.35134868469238284}}}\n",
      "#metrics {\"StartTime\": 1718551207.0204957, \"EndTime\": 1718551207.0205138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3185995320638021, \"count\": 1, \"min\": 0.3185995320638021, \"max\": 0.3185995320638021}}}\n",
      "#metrics {\"StartTime\": 1718551207.020575, \"EndTime\": 1718551207.0205925, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.33515506490071617, \"count\": 1, \"min\": 0.33515506490071617, \"max\": 0.33515506490071617}}}\n",
      "#metrics {\"StartTime\": 1718551207.0206733, \"EndTime\": 1718551207.0206916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30526651509602865, \"count\": 1, \"min\": 0.30526651509602865, \"max\": 0.30526651509602865}}}\n",
      "#metrics {\"StartTime\": 1718551207.020754, \"EndTime\": 1718551207.0207713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3050787851969401, \"count\": 1, \"min\": 0.3050787851969401, \"max\": 0.3050787851969401}}}\n",
      "#metrics {\"StartTime\": 1718551207.0208251, \"EndTime\": 1718551207.0208411, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3051705332438151, \"count\": 1, \"min\": 0.3051705332438151, \"max\": 0.3051705332438151}}}\n",
      "#metrics {\"StartTime\": 1718551207.0209012, \"EndTime\": 1718551207.0209172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30374471944173176, \"count\": 1, \"min\": 0.30374471944173176, \"max\": 0.30374471944173176}}}\n",
      "#metrics {\"StartTime\": 1718551207.020972, \"EndTime\": 1718551207.0209875, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.33050273234049476, \"count\": 1, \"min\": 0.33050273234049476, \"max\": 0.33050273234049476}}}\n",
      "#metrics {\"StartTime\": 1718551207.021047, \"EndTime\": 1718551207.0210633, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3262292419433594, \"count\": 1, \"min\": 0.3262292419433594, \"max\": 0.3262292419433594}}}\n",
      "#metrics {\"StartTime\": 1718551207.0211236, \"EndTime\": 1718551207.0211413, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3382130564371745, \"count\": 1, \"min\": 0.3382130564371745, \"max\": 0.3382130564371745}}}\n",
      "#metrics {\"StartTime\": 1718551207.0211945, \"EndTime\": 1718551207.0212104, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30931682637532554, \"count\": 1, \"min\": 0.30931682637532554, \"max\": 0.30931682637532554}}}\n",
      "#metrics {\"StartTime\": 1718551207.02127, \"EndTime\": 1718551207.0212865, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3036951426188151, \"count\": 1, \"min\": 0.3036951426188151, \"max\": 0.3036951426188151}}}\n",
      "#metrics {\"StartTime\": 1718551207.0213385, \"EndTime\": 1718551207.0213542, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30543078918457034, \"count\": 1, \"min\": 0.30543078918457034, \"max\": 0.30543078918457034}}}\n",
      "#metrics {\"StartTime\": 1718551207.021406, \"EndTime\": 1718551207.0214221, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3053128428141276, \"count\": 1, \"min\": 0.3053128428141276, \"max\": 0.3053128428141276}}}\n",
      "#metrics {\"StartTime\": 1718551207.0214834, \"EndTime\": 1718551207.0215006, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3060045644124349, \"count\": 1, \"min\": 0.3060045644124349, \"max\": 0.3060045644124349}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #quality_metric: host=algo-1, epoch=3, train mse_objective <loss>=0.3204693450927734\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=mse_objective, value=0.3036951426188151\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Epoch 3: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saving model for epoch: 3\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saved checkpoint to \"/tmp/tmpz4840_ku/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\n",
      "#metrics {\"StartTime\": 1718551206.8541057, \"EndTime\": 1718551207.030353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 72516.0, \"count\": 1, \"min\": 72516, \"max\": 72516}, \"Total Batches Seen\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=85767.65070993641 records/second\n",
      "[2024-06-16 15:20:07.211] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 180, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551207.2114098, \"EndTime\": 1718551207.2114847, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30706164245605466, \"count\": 1, \"min\": 0.30706164245605466, \"max\": 0.30706164245605466}}}\n",
      "#metrics {\"StartTime\": 1718551207.2115939, \"EndTime\": 1718551207.211616, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3244313293457031, \"count\": 1, \"min\": 0.3244313293457031, \"max\": 0.3244313293457031}}}\n",
      "#metrics {\"StartTime\": 1718551207.211672, \"EndTime\": 1718551207.2116892, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3031042460123698, \"count\": 1, \"min\": 0.3031042460123698, \"max\": 0.3031042460123698}}}\n",
      "#metrics {\"StartTime\": 1718551207.2117417, \"EndTime\": 1718551207.2117567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31084886067708334, \"count\": 1, \"min\": 0.31084886067708334, \"max\": 0.31084886067708334}}}\n",
      "#metrics {\"StartTime\": 1718551207.2118094, \"EndTime\": 1718551207.2118237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3046882059733073, \"count\": 1, \"min\": 0.3046882059733073, \"max\": 0.3046882059733073}}}\n",
      "#metrics {\"StartTime\": 1718551207.2118719, \"EndTime\": 1718551207.2118883, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3070538299560547, \"count\": 1, \"min\": 0.3070538299560547, \"max\": 0.3070538299560547}}}\n",
      "#metrics {\"StartTime\": 1718551207.211936, \"EndTime\": 1718551207.2119503, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3041479695638021, \"count\": 1, \"min\": 0.3041479695638021, \"max\": 0.3041479695638021}}}\n",
      "#metrics {\"StartTime\": 1718551207.2120004, \"EndTime\": 1718551207.2120152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30439935404459634, \"count\": 1, \"min\": 0.30439935404459634, \"max\": 0.30439935404459634}}}\n",
      "#metrics {\"StartTime\": 1718551207.2120628, \"EndTime\": 1718551207.2120774, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3124235280354818, \"count\": 1, \"min\": 0.3124235280354818, \"max\": 0.3124235280354818}}}\n",
      "#metrics {\"StartTime\": 1718551207.2121272, \"EndTime\": 1718551207.2121422, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3088687947591146, \"count\": 1, \"min\": 0.3088687947591146, \"max\": 0.3088687947591146}}}\n",
      "#metrics {\"StartTime\": 1718551207.212187, \"EndTime\": 1718551207.2122009, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3154735585530599, \"count\": 1, \"min\": 0.3154735585530599, \"max\": 0.3154735585530599}}}\n",
      "#metrics {\"StartTime\": 1718551207.212247, \"EndTime\": 1718551207.2122602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3000582529703776, \"count\": 1, \"min\": 0.3000582529703776, \"max\": 0.3000582529703776}}}\n",
      "#metrics {\"StartTime\": 1718551207.2123013, \"EndTime\": 1718551207.212313, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3050105163574219, \"count\": 1, \"min\": 0.3050105163574219, \"max\": 0.3050105163574219}}}\n",
      "#metrics {\"StartTime\": 1718551207.2123535, \"EndTime\": 1718551207.2123685, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3052706095377604, \"count\": 1, \"min\": 0.3052706095377604, \"max\": 0.3052706095377604}}}\n",
      "#metrics {\"StartTime\": 1718551207.2124164, \"EndTime\": 1718551207.2124317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30597021891276044, \"count\": 1, \"min\": 0.30597021891276044, \"max\": 0.30597021891276044}}}\n",
      "#metrics {\"StartTime\": 1718551207.2124832, \"EndTime\": 1718551207.2124977, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3066702341715495, \"count\": 1, \"min\": 0.3066702341715495, \"max\": 0.3066702341715495}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #quality_metric: host=algo-1, epoch=4, train mse_objective <loss>=0.30706164245605466\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=mse_objective, value=0.3000582529703776\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Epoch 4: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saving model for epoch: 4\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saved checkpoint to \"/tmp/tmp7wqzrya3/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\n",
      "#metrics {\"StartTime\": 1718551207.0306811, \"EndTime\": 1718551207.2238472, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 87645.0, \"count\": 1, \"min\": 87645, \"max\": 87645}, \"Total Batches Seen\": {\"sum\": 92.0, \"count\": 1, \"min\": 92, \"max\": 92}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=78257.09365230292 records/second\n",
      "[2024-06-16 15:20:07.412] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 188, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551207.4129856, \"EndTime\": 1718551207.4130504, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3003584889729818, \"count\": 1, \"min\": 0.3003584889729818, \"max\": 0.3003584889729818}}}\n",
      "#metrics {\"StartTime\": 1718551207.4131503, \"EndTime\": 1718551207.4131687, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31049636637369793, \"count\": 1, \"min\": 0.31049636637369793, \"max\": 0.31049636637369793}}}\n",
      "#metrics {\"StartTime\": 1718551207.4132292, \"EndTime\": 1718551207.413316, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.297237690226237, \"count\": 1, \"min\": 0.297237690226237, \"max\": 0.297237690226237}}}\n",
      "#metrics {\"StartTime\": 1718551207.4133742, \"EndTime\": 1718551207.4134212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30068653259277345, \"count\": 1, \"min\": 0.30068653259277345, \"max\": 0.30068653259277345}}}\n",
      "#metrics {\"StartTime\": 1718551207.4134796, \"EndTime\": 1718551207.4134927, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3035849161783854, \"count\": 1, \"min\": 0.3035849161783854, \"max\": 0.3035849161783854}}}\n",
      "#metrics {\"StartTime\": 1718551207.413534, \"EndTime\": 1718551207.4135447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30602006022135414, \"count\": 1, \"min\": 0.30602006022135414, \"max\": 0.30602006022135414}}}\n",
      "#metrics {\"StartTime\": 1718551207.4136338, \"EndTime\": 1718551207.413648, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30278334045410155, \"count\": 1, \"min\": 0.30278334045410155, \"max\": 0.30278334045410155}}}\n",
      "#metrics {\"StartTime\": 1718551207.4137142, \"EndTime\": 1718551207.41373, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3052166442871094, \"count\": 1, \"min\": 0.3052166442871094, \"max\": 0.3052166442871094}}}\n",
      "#metrics {\"StartTime\": 1718551207.4137843, \"EndTime\": 1718551207.413797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3032330444335937, \"count\": 1, \"min\": 0.3032330444335937, \"max\": 0.3032330444335937}}}\n",
      "#metrics {\"StartTime\": 1718551207.4138854, \"EndTime\": 1718551207.413901, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3005385030110677, \"count\": 1, \"min\": 0.3005385030110677, \"max\": 0.3005385030110677}}}\n",
      "#metrics {\"StartTime\": 1718551207.4139543, \"EndTime\": 1718551207.4139662, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30371138610839843, \"count\": 1, \"min\": 0.30371138610839843, \"max\": 0.30371138610839843}}}\n",
      "#metrics {\"StartTime\": 1718551207.4140518, \"EndTime\": 1718551207.414068, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2957102996826172, \"count\": 1, \"min\": 0.2957102996826172, \"max\": 0.2957102996826172}}}\n",
      "#metrics {\"StartTime\": 1718551207.414121, \"EndTime\": 1718551207.414133, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30456189982096354, \"count\": 1, \"min\": 0.30456189982096354, \"max\": 0.30456189982096354}}}\n",
      "#metrics {\"StartTime\": 1718551207.4142265, \"EndTime\": 1718551207.414242, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3034847869873047, \"count\": 1, \"min\": 0.3034847869873047, \"max\": 0.3034847869873047}}}\n",
      "#metrics {\"StartTime\": 1718551207.414317, \"EndTime\": 1718551207.414332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30370921020507813, \"count\": 1, \"min\": 0.30370921020507813, \"max\": 0.30370921020507813}}}\n",
      "#metrics {\"StartTime\": 1718551207.414376, \"EndTime\": 1718551207.414387, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30598473510742186, \"count\": 1, \"min\": 0.30598473510742186, \"max\": 0.30598473510742186}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #quality_metric: host=algo-1, epoch=5, train mse_objective <loss>=0.3003584889729818\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=mse_objective, value=0.2957102996826172\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Epoch 5: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saving model for epoch: 5\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saved checkpoint to \"/tmp/tmp2v7exjrv/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #progress_metric: host=algo-1, completed 40.0 % of epochs\n",
      "#metrics {\"StartTime\": 1718551207.2241802, \"EndTime\": 1718551207.4233515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 102774.0, \"count\": 1, \"min\": 102774, \"max\": 102774}, \"Total Batches Seen\": {\"sum\": 108.0, \"count\": 1, \"min\": 108, \"max\": 108}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=75907.3082460686 records/second\n",
      "[2024-06-16 15:20:07.613] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 189, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551207.6138515, \"EndTime\": 1718551207.6139233, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29656476033528645, \"count\": 1, \"min\": 0.29656476033528645, \"max\": 0.29656476033528645}}}\n",
      "#metrics {\"StartTime\": 1718551207.6140125, \"EndTime\": 1718551207.614034, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3027329060872396, \"count\": 1, \"min\": 0.3027329060872396, \"max\": 0.3027329060872396}}}\n",
      "#metrics {\"StartTime\": 1718551207.6140833, \"EndTime\": 1718551207.614098, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2946292714436849, \"count\": 1, \"min\": 0.2946292714436849, \"max\": 0.2946292714436849}}}\n",
      "#metrics {\"StartTime\": 1718551207.6142297, \"EndTime\": 1718551207.6142502, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2963780527750651, \"count\": 1, \"min\": 0.2963780527750651, \"max\": 0.2963780527750651}}}\n",
      "#metrics {\"StartTime\": 1718551207.6144137, \"EndTime\": 1718551207.6144345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3042964803059896, \"count\": 1, \"min\": 0.3042964803059896, \"max\": 0.3042964803059896}}}\n",
      "#metrics {\"StartTime\": 1718551207.6145318, \"EndTime\": 1718551207.6145504, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3064732666015625, \"count\": 1, \"min\": 0.3064732666015625, \"max\": 0.3064732666015625}}}\n",
      "#metrics {\"StartTime\": 1718551207.6146345, \"EndTime\": 1718551207.6146555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3032508310953776, \"count\": 1, \"min\": 0.3032508310953776, \"max\": 0.3032508310953776}}}\n",
      "#metrics {\"StartTime\": 1718551207.6147056, \"EndTime\": 1718551207.6147208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3071644358317057, \"count\": 1, \"min\": 0.3071644358317057, \"max\": 0.3071644358317057}}}\n",
      "#metrics {\"StartTime\": 1718551207.6148105, \"EndTime\": 1718551207.6148298, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2979345672607422, \"count\": 1, \"min\": 0.2979345672607422, \"max\": 0.2979345672607422}}}\n",
      "#metrics {\"StartTime\": 1718551207.6148798, \"EndTime\": 1718551207.6148944, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2963609893798828, \"count\": 1, \"min\": 0.2963609893798828, \"max\": 0.2963609893798828}}}\n",
      "#metrics {\"StartTime\": 1718551207.6149392, \"EndTime\": 1718551207.6149535, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29763983459472654, \"count\": 1, \"min\": 0.29763983459472654, \"max\": 0.29763983459472654}}}\n",
      "#metrics {\"StartTime\": 1718551207.615005, \"EndTime\": 1718551207.6150198, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2934081288655599, \"count\": 1, \"min\": 0.2934081288655599, \"max\": 0.2934081288655599}}}\n",
      "#metrics {\"StartTime\": 1718551207.6150682, \"EndTime\": 1718551207.6150835, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3043108103434245, \"count\": 1, \"min\": 0.3043108103434245, \"max\": 0.3043108103434245}}}\n",
      "#metrics {\"StartTime\": 1718551207.6151235, \"EndTime\": 1718551207.6151369, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30482005513509114, \"count\": 1, \"min\": 0.30482005513509114, \"max\": 0.30482005513509114}}}\n",
      "#metrics {\"StartTime\": 1718551207.6151824, \"EndTime\": 1718551207.6151974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3034831553141276, \"count\": 1, \"min\": 0.3034831553141276, \"max\": 0.3034831553141276}}}\n",
      "#metrics {\"StartTime\": 1718551207.6152432, \"EndTime\": 1718551207.6152585, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30651043497721353, \"count\": 1, \"min\": 0.30651043497721353, \"max\": 0.30651043497721353}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #quality_metric: host=algo-1, epoch=6, train mse_objective <loss>=0.29656476033528645\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=mse_objective, value=0.2934081288655599\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Epoch 6: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saving model for epoch: 6\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saved checkpoint to \"/tmp/tmpurbnzyzb/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\n",
      "#metrics {\"StartTime\": 1718551207.4236705, \"EndTime\": 1718551207.623885, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 117903.0, \"count\": 1, \"min\": 117903, \"max\": 117903}, \"Total Batches Seen\": {\"sum\": 124.0, \"count\": 1, \"min\": 124, \"max\": 124}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=75515.17157025501 records/second\n",
      "[2024-06-16 15:20:07.834] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 210, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551207.8348732, \"EndTime\": 1718551207.8349469, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2944434265136719, \"count\": 1, \"min\": 0.2944434265136719, \"max\": 0.2944434265136719}}}\n",
      "#metrics {\"StartTime\": 1718551207.8350525, \"EndTime\": 1718551207.8350735, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2983146230061849, \"count\": 1, \"min\": 0.2983146230061849, \"max\": 0.2983146230061849}}}\n",
      "#metrics {\"StartTime\": 1718551207.8351254, \"EndTime\": 1718551207.835142, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29329923502604166, \"count\": 1, \"min\": 0.29329923502604166, \"max\": 0.29329923502604166}}}\n",
      "#metrics {\"StartTime\": 1718551207.835195, \"EndTime\": 1718551207.8352115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2943832987467448, \"count\": 1, \"min\": 0.2943832987467448, \"max\": 0.2943832987467448}}}\n",
      "#metrics {\"StartTime\": 1718551207.83526, \"EndTime\": 1718551207.8352754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3047851989746094, \"count\": 1, \"min\": 0.3047851989746094, \"max\": 0.3047851989746094}}}\n",
      "#metrics {\"StartTime\": 1718551207.8353226, \"EndTime\": 1718551207.8353379, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3067773366292318, \"count\": 1, \"min\": 0.3067773366292318, \"max\": 0.3067773366292318}}}\n",
      "#metrics {\"StartTime\": 1718551207.8354173, \"EndTime\": 1718551207.835434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30368239135742187, \"count\": 1, \"min\": 0.30368239135742187, \"max\": 0.30368239135742187}}}\n",
      "#metrics {\"StartTime\": 1718551207.8354847, \"EndTime\": 1718551207.8354998, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30861895650227866, \"count\": 1, \"min\": 0.30861895650227866, \"max\": 0.30861895650227866}}}\n",
      "#metrics {\"StartTime\": 1718551207.8355463, \"EndTime\": 1718551207.8355608, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2948657684326172, \"count\": 1, \"min\": 0.2948657684326172, \"max\": 0.2948657684326172}}}\n",
      "#metrics {\"StartTime\": 1718551207.8356066, \"EndTime\": 1718551207.835621, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29417923380533856, \"count\": 1, \"min\": 0.29417923380533856, \"max\": 0.29417923380533856}}}\n",
      "#metrics {\"StartTime\": 1718551207.8356702, \"EndTime\": 1718551207.8356848, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2945227600097656, \"count\": 1, \"min\": 0.2945227600097656, \"max\": 0.2945227600097656}}}\n",
      "#metrics {\"StartTime\": 1718551207.8357322, \"EndTime\": 1718551207.835748, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2922594248453776, \"count\": 1, \"min\": 0.2922594248453776, \"max\": 0.2922594248453776}}}\n",
      "#metrics {\"StartTime\": 1718551207.835797, \"EndTime\": 1718551207.8358114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3038245147705078, \"count\": 1, \"min\": 0.3038245147705078, \"max\": 0.3038245147705078}}}\n",
      "#metrics {\"StartTime\": 1718551207.8358572, \"EndTime\": 1718551207.8358717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3059181976318359, \"count\": 1, \"min\": 0.3059181976318359, \"max\": 0.3059181976318359}}}\n",
      "#metrics {\"StartTime\": 1718551207.8359165, \"EndTime\": 1718551207.8359313, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3036407165527344, \"count\": 1, \"min\": 0.3036407165527344, \"max\": 0.3036407165527344}}}\n",
      "#metrics {\"StartTime\": 1718551207.835982, \"EndTime\": 1718551207.8359973, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30774095967610676, \"count\": 1, \"min\": 0.30774095967610676, \"max\": 0.30774095967610676}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #quality_metric: host=algo-1, epoch=7, train mse_objective <loss>=0.2944434265136719\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=mse_objective, value=0.2922594248453776\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Epoch 7: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saving model for epoch: 7\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] Saved checkpoint to \"/tmp/tmptu5rwovt/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\n",
      "#metrics {\"StartTime\": 1718551207.624179, \"EndTime\": 1718551207.8465014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 133032.0, \"count\": 1, \"min\": 133032, \"max\": 133032}, \"Total Batches Seen\": {\"sum\": 140.0, \"count\": 1, \"min\": 140, \"max\": 140}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:07 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=68004.36948658842 records/second\n",
      "[2024-06-16 15:20:08.065] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 218, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551208.065843, \"EndTime\": 1718551208.0659099, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2932236012776693, \"count\": 1, \"min\": 0.2932236012776693, \"max\": 0.2932236012776693}}}\n",
      "#metrics {\"StartTime\": 1718551208.0661056, \"EndTime\": 1718551208.0661619, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29573041890462237, \"count\": 1, \"min\": 0.29573041890462237, \"max\": 0.29573041890462237}}}\n",
      "#metrics {\"StartTime\": 1718551208.066272, \"EndTime\": 1718551208.0662897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29250130920410156, \"count\": 1, \"min\": 0.29250130920410156, \"max\": 0.29250130920410156}}}\n",
      "#metrics {\"StartTime\": 1718551208.066366, \"EndTime\": 1718551208.0663786, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2933340779622396, \"count\": 1, \"min\": 0.2933340779622396, \"max\": 0.2933340779622396}}}\n",
      "#metrics {\"StartTime\": 1718551208.0664988, \"EndTime\": 1718551208.0665152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30548941548665365, \"count\": 1, \"min\": 0.30548941548665365, \"max\": 0.30548941548665365}}}\n",
      "#metrics {\"StartTime\": 1718551208.0665908, \"EndTime\": 1718551208.0666032, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30774410095214844, \"count\": 1, \"min\": 0.30774410095214844, \"max\": 0.30774410095214844}}}\n",
      "#metrics {\"StartTime\": 1718551208.0667665, \"EndTime\": 1718551208.066784, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30473291829427085, \"count\": 1, \"min\": 0.30473291829427085, \"max\": 0.30473291829427085}}}\n",
      "#metrics {\"StartTime\": 1718551208.0668602, \"EndTime\": 1718551208.0668728, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3096374572753906, \"count\": 1, \"min\": 0.3096374572753906, \"max\": 0.3096374572753906}}}\n",
      "#metrics {\"StartTime\": 1718551208.0669973, \"EndTime\": 1718551208.0670133, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2931259979248047, \"count\": 1, \"min\": 0.2931259979248047, \"max\": 0.2931259979248047}}}\n",
      "#metrics {\"StartTime\": 1718551208.0670915, \"EndTime\": 1718551208.0671039, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29301148579915365, \"count\": 1, \"min\": 0.29301148579915365, \"max\": 0.29301148579915365}}}\n",
      "#metrics {\"StartTime\": 1718551208.067214, \"EndTime\": 1718551208.0672362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.292925005086263, \"count\": 1, \"min\": 0.292925005086263, \"max\": 0.292925005086263}}}\n",
      "#metrics {\"StartTime\": 1718551208.0672886, \"EndTime\": 1718551208.0673048, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29171411641438805, \"count\": 1, \"min\": 0.29171411641438805, \"max\": 0.29171411641438805}}}\n",
      "#metrics {\"StartTime\": 1718551208.0673566, \"EndTime\": 1718551208.067371, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30433387247721355, \"count\": 1, \"min\": 0.30433387247721355, \"max\": 0.30433387247721355}}}\n",
      "#metrics {\"StartTime\": 1718551208.0674279, \"EndTime\": 1718551208.0674431, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3070268046061198, \"count\": 1, \"min\": 0.3070268046061198, \"max\": 0.3070268046061198}}}\n",
      "#metrics {\"StartTime\": 1718551208.067491, \"EndTime\": 1718551208.067507, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3044373199462891, \"count\": 1, \"min\": 0.3044373199462891, \"max\": 0.3044373199462891}}}\n",
      "#metrics {\"StartTime\": 1718551208.0675561, \"EndTime\": 1718551208.0675716, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3088123677571615, \"count\": 1, \"min\": 0.3088123677571615, \"max\": 0.3088123677571615}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #quality_metric: host=algo-1, epoch=8, train mse_objective <loss>=0.2932236012776693\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=mse_objective, value=0.29171411641438805\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Epoch 8: Loss improved. Updating best model\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saving model for epoch: 8\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saved checkpoint to \"/tmp/tmpgc3wkx4a/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #progress_metric: host=algo-1, completed 60.0 % of epochs\n",
      "#metrics {\"StartTime\": 1718551207.8468235, \"EndTime\": 1718551208.078949, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 148161.0, \"count\": 1, \"min\": 148161, \"max\": 148161}, \"Total Batches Seen\": {\"sum\": 156.0, \"count\": 1, \"min\": 156, \"max\": 156}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=65135.535820342455 records/second\n",
      "[2024-06-16 15:20:08.314] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 235, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551208.3149028, \"EndTime\": 1718551208.3149812, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2925133331298828, \"count\": 1, \"min\": 0.2925133331298828, \"max\": 0.2925133331298828}}}\n",
      "#metrics {\"StartTime\": 1718551208.315417, \"EndTime\": 1718551208.315448, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2941563212076823, \"count\": 1, \"min\": 0.2941563212076823, \"max\": 0.2941563212076823}}}\n",
      "#metrics {\"StartTime\": 1718551208.31583, \"EndTime\": 1718551208.3158565, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29199490051269533, \"count\": 1, \"min\": 0.29199490051269533, \"max\": 0.29199490051269533}}}\n",
      "#metrics {\"StartTime\": 1718551208.3162358, \"EndTime\": 1718551208.3162603, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2927071990966797, \"count\": 1, \"min\": 0.2927071990966797, \"max\": 0.2927071990966797}}}\n",
      "#metrics {\"StartTime\": 1718551208.3166227, \"EndTime\": 1718551208.3166487, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3059160614013672, \"count\": 1, \"min\": 0.3059160614013672, \"max\": 0.3059160614013672}}}\n",
      "#metrics {\"StartTime\": 1718551208.3170137, \"EndTime\": 1718551208.3170378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30905193786621094, \"count\": 1, \"min\": 0.30905193786621094, \"max\": 0.30905193786621094}}}\n",
      "#metrics {\"StartTime\": 1718551208.3173633, \"EndTime\": 1718551208.317388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30534574788411456, \"count\": 1, \"min\": 0.30534574788411456, \"max\": 0.30534574788411456}}}\n",
      "#metrics {\"StartTime\": 1718551208.3177226, \"EndTime\": 1718551208.3177476, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.310986171468099, \"count\": 1, \"min\": 0.310986171468099, \"max\": 0.310986171468099}}}\n",
      "#metrics {\"StartTime\": 1718551208.318099, \"EndTime\": 1718551208.3181255, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2921616465250651, \"count\": 1, \"min\": 0.2921616465250651, \"max\": 0.2921616465250651}}}\n",
      "#metrics {\"StartTime\": 1718551208.3184621, \"EndTime\": 1718551208.318488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2923508280436198, \"count\": 1, \"min\": 0.2923508280436198, \"max\": 0.2923508280436198}}}\n",
      "#metrics {\"StartTime\": 1718551208.3189301, \"EndTime\": 1718551208.3189564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29210031026204425, \"count\": 1, \"min\": 0.29210031026204425, \"max\": 0.29210031026204425}}}\n",
      "#metrics {\"StartTime\": 1718551208.3194382, \"EndTime\": 1718551208.3194652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29145328267415366, \"count\": 1, \"min\": 0.29145328267415366, \"max\": 0.29145328267415366}}}\n",
      "#metrics {\"StartTime\": 1718551208.3198094, \"EndTime\": 1718551208.3198357, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3047903940836589, \"count\": 1, \"min\": 0.3047903940836589, \"max\": 0.3047903940836589}}}\n",
      "#metrics {\"StartTime\": 1718551208.3201644, \"EndTime\": 1718551208.3201892, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30831676127115887, \"count\": 1, \"min\": 0.30831676127115887, \"max\": 0.30831676127115887}}}\n",
      "#metrics {\"StartTime\": 1718551208.3205957, \"EndTime\": 1718551208.320622, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3049470947265625, \"count\": 1, \"min\": 0.3049470947265625, \"max\": 0.3049470947265625}}}\n",
      "#metrics {\"StartTime\": 1718551208.3210316, \"EndTime\": 1718551208.3210573, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3104913411458333, \"count\": 1, \"min\": 0.3104913411458333, \"max\": 0.3104913411458333}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #quality_metric: host=algo-1, epoch=9, train mse_objective <loss>=0.2925133331298828\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=mse_objective, value=0.29145328267415366\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saving model for epoch: 9\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saved checkpoint to \"/tmp/tmpbaet3lwq/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\n",
      "#metrics {\"StartTime\": 1718551208.0792594, \"EndTime\": 1718551208.3333662, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 163290.0, \"count\": 1, \"min\": 163290, \"max\": 163290}, \"Total Batches Seen\": {\"sum\": 172.0, \"count\": 1, \"min\": 172, \"max\": 172}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=59427.84368257013 records/second\n",
      "[2024-06-16 15:20:08.580] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 246, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551208.5809317, \"EndTime\": 1718551208.5809813, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2920732727050781, \"count\": 1, \"min\": 0.2920732727050781, \"max\": 0.2920732727050781}}}\n",
      "#metrics {\"StartTime\": 1718551208.581109, \"EndTime\": 1718551208.581133, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2931699259440104, \"count\": 1, \"min\": 0.2931699259440104, \"max\": 0.2931699259440104}}}\n",
      "#metrics {\"StartTime\": 1718551208.5811877, \"EndTime\": 1718551208.581204, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2916588073730469, \"count\": 1, \"min\": 0.2916588073730469, \"max\": 0.2916588073730469}}}\n",
      "#metrics {\"StartTime\": 1718551208.5814228, \"EndTime\": 1718551208.5814514, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29229868774414064, \"count\": 1, \"min\": 0.29229868774414064, \"max\": 0.29229868774414064}}}\n",
      "#metrics {\"StartTime\": 1718551208.581515, \"EndTime\": 1718551208.5815313, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3062788208007812, \"count\": 1, \"min\": 0.3062788208007812, \"max\": 0.3062788208007812}}}\n",
      "#metrics {\"StartTime\": 1718551208.5815818, \"EndTime\": 1718551208.5815985, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31046073404947916, \"count\": 1, \"min\": 0.31046073404947916, \"max\": 0.31046073404947916}}}\n",
      "#metrics {\"StartTime\": 1718551208.5816486, \"EndTime\": 1718551208.581665, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3058552551269531, \"count\": 1, \"min\": 0.3058552551269531, \"max\": 0.3058552551269531}}}\n",
      "#metrics {\"StartTime\": 1718551208.5817175, \"EndTime\": 1718551208.5817335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3117775197347005, \"count\": 1, \"min\": 0.3117775197347005, \"max\": 0.3117775197347005}}}\n",
      "#metrics {\"StartTime\": 1718551208.58178, \"EndTime\": 1718551208.5817952, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29163199361165365, \"count\": 1, \"min\": 0.29163199361165365, \"max\": 0.29163199361165365}}}\n",
      "#metrics {\"StartTime\": 1718551208.5818424, \"EndTime\": 1718551208.5818584, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2919581705729167, \"count\": 1, \"min\": 0.2919581705729167, \"max\": 0.2919581705729167}}}\n",
      "#metrics {\"StartTime\": 1718551208.5819058, \"EndTime\": 1718551208.5819216, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2916647888183594, \"count\": 1, \"min\": 0.2916647888183594, \"max\": 0.2916647888183594}}}\n",
      "#metrics {\"StartTime\": 1718551208.5819695, \"EndTime\": 1718551208.5819843, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2913263936360677, \"count\": 1, \"min\": 0.2913263936360677, \"max\": 0.2913263936360677}}}\n",
      "#metrics {\"StartTime\": 1718551208.5820305, \"EndTime\": 1718551208.5820465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30526456197102864, \"count\": 1, \"min\": 0.30526456197102864, \"max\": 0.30526456197102864}}}\n",
      "#metrics {\"StartTime\": 1718551208.582093, \"EndTime\": 1718551208.5821092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30962649943033854, \"count\": 1, \"min\": 0.30962649943033854, \"max\": 0.30962649943033854}}}\n",
      "#metrics {\"StartTime\": 1718551208.582156, \"EndTime\": 1718551208.582172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3054336893717448, \"count\": 1, \"min\": 0.3054336893717448, \"max\": 0.3054336893717448}}}\n",
      "#metrics {\"StartTime\": 1718551208.5822194, \"EndTime\": 1718551208.582235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3113485310872396, \"count\": 1, \"min\": 0.3113485310872396, \"max\": 0.3113485310872396}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #quality_metric: host=algo-1, epoch=10, train mse_objective <loss>=0.2920732727050781\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=mse_objective, value=0.2913263936360677\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saving model for epoch: 10\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saved checkpoint to \"/tmp/tmp8fzlbbe8/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #progress_metric: host=algo-1, completed 73.33333333333333 % of epochs\n",
      "#metrics {\"StartTime\": 1718551208.3343012, \"EndTime\": 1718551208.5910938, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 178419.0, \"count\": 1, \"min\": 178419, \"max\": 178419}, \"Total Batches Seen\": {\"sum\": 188.0, \"count\": 1, \"min\": 188, \"max\": 188}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=58880.00142524295 records/second\n",
      "[2024-06-16 15:20:08.788] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 196, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551208.7883437, \"EndTime\": 1718551208.7884133, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2917890319824219, \"count\": 1, \"min\": 0.2917890319824219, \"max\": 0.2917890319824219}}}\n",
      "#metrics {\"StartTime\": 1718551208.7885156, \"EndTime\": 1718551208.7885332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2925359069824219, \"count\": 1, \"min\": 0.2925359069824219, \"max\": 0.2925359069824219}}}\n",
      "#metrics {\"StartTime\": 1718551208.7885878, \"EndTime\": 1718551208.7886007, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2914349324544271, \"count\": 1, \"min\": 0.2914349324544271, \"max\": 0.2914349324544271}}}\n",
      "#metrics {\"StartTime\": 1718551208.7886674, \"EndTime\": 1718551208.7886808, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2920134114583333, \"count\": 1, \"min\": 0.2920134114583333, \"max\": 0.2920134114583333}}}\n",
      "#metrics {\"StartTime\": 1718551208.788733, \"EndTime\": 1718551208.7887452, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30648507181803386, \"count\": 1, \"min\": 0.30648507181803386, \"max\": 0.30648507181803386}}}\n",
      "#metrics {\"StartTime\": 1718551208.788782, \"EndTime\": 1718551208.788793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31173655598958333, \"count\": 1, \"min\": 0.31173655598958333, \"max\": 0.31173655598958333}}}\n",
      "#metrics {\"StartTime\": 1718551208.7888343, \"EndTime\": 1718551208.788845, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30615302734375, \"count\": 1, \"min\": 0.30615302734375, \"max\": 0.30615302734375}}}\n",
      "#metrics {\"StartTime\": 1718551208.7888882, \"EndTime\": 1718551208.7888992, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31292120564778647, \"count\": 1, \"min\": 0.31292120564778647, \"max\": 0.31292120564778647}}}\n",
      "#metrics {\"StartTime\": 1718551208.7889411, \"EndTime\": 1718551208.7889526, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2913469228108724, \"count\": 1, \"min\": 0.2913469228108724, \"max\": 0.2913469228108724}}}\n",
      "#metrics {\"StartTime\": 1718551208.7890067, \"EndTime\": 1718551208.7890184, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29171011555989584, \"count\": 1, \"min\": 0.29171011555989584, \"max\": 0.29171011555989584}}}\n",
      "#metrics {\"StartTime\": 1718551208.7890635, \"EndTime\": 1718551208.789074, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2914302998860677, \"count\": 1, \"min\": 0.2914302998860677, \"max\": 0.2914302998860677}}}\n",
      "#metrics {\"StartTime\": 1718551208.7891111, \"EndTime\": 1718551208.7891207, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2912617889404297, \"count\": 1, \"min\": 0.2912617889404297, \"max\": 0.2912617889404297}}}\n",
      "#metrics {\"StartTime\": 1718551208.7891574, \"EndTime\": 1718551208.7891686, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.305585492960612, \"count\": 1, \"min\": 0.305585492960612, \"max\": 0.305585492960612}}}\n",
      "#metrics {\"StartTime\": 1718551208.7892153, \"EndTime\": 1718551208.7892265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31073234558105467, \"count\": 1, \"min\": 0.31073234558105467, \"max\": 0.31073234558105467}}}\n",
      "#metrics {\"StartTime\": 1718551208.789265, \"EndTime\": 1718551208.7892747, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30575465189615886, \"count\": 1, \"min\": 0.30575465189615886, \"max\": 0.30575465189615886}}}\n",
      "#metrics {\"StartTime\": 1718551208.7893076, \"EndTime\": 1718551208.789317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.312731679280599, \"count\": 1, \"min\": 0.312731679280599, \"max\": 0.312731679280599}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #quality_metric: host=algo-1, epoch=11, train mse_objective <loss>=0.2917890319824219\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=mse_objective, value=0.2912617889404297\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saving model for epoch: 11\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] Saved checkpoint to \"/tmp/tmpmrx_aamu/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #progress_metric: host=algo-1, completed 80.0 % of epochs\n",
      "#metrics {\"StartTime\": 1718551208.5914237, \"EndTime\": 1718551208.797405, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 193548.0, \"count\": 1, \"min\": 193548, \"max\": 193548}, \"Total Batches Seen\": {\"sum\": 204.0, \"count\": 1, \"min\": 204, \"max\": 204}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:08 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=73406.11815659972 records/second\n",
      "[2024-06-16 15:20:09.003] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 205, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "#metrics {\"StartTime\": 1718551209.0037386, \"EndTime\": 1718551209.0038145, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 0}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29158972778320313, \"count\": 1, \"min\": 0.29158972778320313, \"max\": 0.29158972778320313}}}\n",
      "#metrics {\"StartTime\": 1718551209.0039806, \"EndTime\": 1718551209.0040324, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 1}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.292116123453776, \"count\": 1, \"min\": 0.292116123453776, \"max\": 0.292116123453776}}}\n",
      "#metrics {\"StartTime\": 1718551209.004122, \"EndTime\": 1718551209.0041425, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 2}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29128073018391926, \"count\": 1, \"min\": 0.29128073018391926, \"max\": 0.29128073018391926}}}\n",
      "#metrics {\"StartTime\": 1718551209.0042546, \"EndTime\": 1718551209.0042741, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 3}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29180269978841145, \"count\": 1, \"min\": 0.29180269978841145, \"max\": 0.29180269978841145}}}\n",
      "#metrics {\"StartTime\": 1718551209.0045028, \"EndTime\": 1718551209.004528, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 4}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3066767425537109, \"count\": 1, \"min\": 0.3066767425537109, \"max\": 0.3066767425537109}}}\n",
      "#metrics {\"StartTime\": 1718551209.0045896, \"EndTime\": 1718551209.0046072, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 5}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31273434041341147, \"count\": 1, \"min\": 0.31273434041341147, \"max\": 0.31273434041341147}}}\n",
      "#metrics {\"StartTime\": 1718551209.0047715, \"EndTime\": 1718551209.0047917, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 6}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3063893747965495, \"count\": 1, \"min\": 0.3063893747965495, \"max\": 0.3063893747965495}}}\n",
      "#metrics {\"StartTime\": 1718551209.0048826, \"EndTime\": 1718551209.0049012, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 7}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31357024434407554, \"count\": 1, \"min\": 0.31357024434407554, \"max\": 0.31357024434407554}}}\n",
      "#metrics {\"StartTime\": 1718551209.0049546, \"EndTime\": 1718551209.0050058, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 8}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2911900370279948, \"count\": 1, \"min\": 0.2911900370279948, \"max\": 0.2911900370279948}}}\n",
      "#metrics {\"StartTime\": 1718551209.0050905, \"EndTime\": 1718551209.00511, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 9}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29154468180338544, \"count\": 1, \"min\": 0.29154468180338544, \"max\": 0.29154468180338544}}}\n",
      "#metrics {\"StartTime\": 1718551209.0051649, \"EndTime\": 1718551209.0051796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 10}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.29129439392089845, \"count\": 1, \"min\": 0.29129439392089845, \"max\": 0.29129439392089845}}}\n",
      "#metrics {\"StartTime\": 1718551209.0052595, \"EndTime\": 1718551209.005279, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 11}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.2912272247314453, \"count\": 1, \"min\": 0.2912272247314453, \"max\": 0.2912272247314453}}}\n",
      "#metrics {\"StartTime\": 1718551209.0053656, \"EndTime\": 1718551209.0053835, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 12}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.30589620361328124, \"count\": 1, \"min\": 0.30589620361328124, \"max\": 0.30589620361328124}}}\n",
      "#metrics {\"StartTime\": 1718551209.005434, \"EndTime\": 1718551209.0054488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 13}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.3116647247314453, \"count\": 1, \"min\": 0.3116647247314453, \"max\": 0.3116647247314453}}}\n",
      "#metrics {\"StartTime\": 1718551209.00554, \"EndTime\": 1718551209.0055587, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 14}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.306044096883138, \"count\": 1, \"min\": 0.306044096883138, \"max\": 0.306044096883138}}}\n",
      "#metrics {\"StartTime\": 1718551209.0056093, \"EndTime\": 1718551209.0056238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 15}, \"Metrics\": {\"train_mse_objective\": {\"sum\": 0.31335274759928383, \"count\": 1, \"min\": 0.31335274759928383, \"max\": 0.31335274759928383}}}\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #quality_metric: host=algo-1, epoch=12, train mse_objective <loss>=0.29158972778320313\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=mse_objective, value=0.2911900370279948\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] Saving model for epoch: 12\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] Saved checkpoint to \"/tmp/tmp8so8uok5/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] Early stop condition met. Stopping training.\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #progress_metric: host=algo-1, completed 100 % epochs\n",
      "#metrics {\"StartTime\": 1718551208.7976348, \"EndTime\": 1718551209.0137482, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 208677.0, \"count\": 1, \"min\": 208677, \"max\": 208677}, \"Total Batches Seen\": {\"sum\": 220.0, \"count\": 1, \"min\": 220, \"max\": 220}, \"Max Records Seen Between Resets\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Max Batches Seen Between Resets\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 15129.0, \"count\": 1, \"min\": 15129, \"max\": 15129}, \"Number of Batches Since Last Reset\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}}}\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #throughput_metric: host=algo-1, train throughput=69943.3616087421 records/second\n",
      "[06/16/2024 15:20:09 WARNING 139954502117184] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[06/16/2024 15:20:09 WARNING 139954502117184] wait_for_all_workers will not sync workers since the kv store is not running distributed\n",
      "[2024-06-16 15:20:09.021] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 6, \"num_examples\": 1, \"num_bytes\": 108000}\n",
      "[2024-06-16 15:20:09.067] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 43, \"num_examples\": 16, \"num_bytes\": 1633932}\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #train_score (algo-1) : ('mse_objective', 39787004382.665344)\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #train_score (algo-1) : ('mse', 39787004382.665344)\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #train_score (algo-1) : ('absolute_loss', 125602.15572741094)\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #train_score (algo-1) : ('rmse', 199466.80020160082)\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #train_score (algo-1) : ('r2', 0.7024091862757823)\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #train_score (algo-1) : ('mae', 125602.15688412981)\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #quality_metric: host=algo-1, train mse_objective <loss>=39787004382.665344\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #quality_metric: host=algo-1, train mse <loss>=39787004382.665344\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #quality_metric: host=algo-1, train absolute_loss <loss>=125602.15572741094\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #quality_metric: host=algo-1, train rmse <loss>=199466.80020160082\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #quality_metric: host=algo-1, train r2 <loss>=0.7024091862757823\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] #quality_metric: host=algo-1, train mae <loss>=125602.15688412981\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.01, \"l1\": 0.0, \"lr_scheduler_step\": 100, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 0.0001}\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] Saved checkpoint to \"/tmp/tmp03m28f8i/mx-mod-0000.params\"\n",
      "[06/16/2024 15:20:09 INFO 139954502117184] Test data is not provided.\n",
      "#metrics {\"StartTime\": 1718551206.1260393, \"EndTime\": 1718551209.0758893, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 174.41463470458984, \"count\": 1, \"min\": 174.41463470458984, \"max\": 174.41463470458984}, \"epochs\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"check_early_stopping.time\": {\"sum\": 14.286994934082031, \"count\": 13, \"min\": 0.2067089080810547, \"max\": 3.278970718383789}, \"update.time\": {\"sum\": 2661.7655754089355, \"count\": 13, \"min\": 171.92816734313965, \"max\": 253.6311149597168}, \"finalize.time\": {\"sum\": 56.359291076660156, \"count\": 1, \"min\": 56.359291076660156, \"max\": 56.359291076660156}, \"setuptime\": {\"sum\": 2.5017261505126953, \"count\": 1, \"min\": 2.5017261505126953, \"max\": 2.5017261505126953}, \"totaltime\": {\"sum\": 3071.956157684326, \"count\": 1, \"min\": 3071.956157684326, \"max\": 3071.956157684326}}}\n",
      "\n",
      "2024-06-16 15:20:29 Uploading - Uploading generated training model\n",
      "2024-06-16 15:20:29 Completed - Training job completed\n",
      "Training seconds: 154\n",
      "Billable seconds: 154\n"
     ]
    }
   ],
   "source": [
    "linear.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy, previsões e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: linear-learner-2024-06-16-15-21-23-090\n",
      "INFO:sagemaker:Creating endpoint-config with name linear-learner-2024-06-16-15-21-23-090\n",
      "INFO:sagemaker:Creating endpoint with name linear-learner-2024-06-16-15-21-23-090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "# https://aws.amazon.com/pt/ec2/instance-types/inf1/\n",
    "linear_regressor = linear.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor.serializer = CSVSerializer()\n",
    "linear_regressor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6484, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = linear_regressor.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 396383.5},\n",
       "  {'score': 1486271.5},\n",
       "  {'score': 541275.5},\n",
       "  {'score': 569959.5},\n",
       "  {'score': 995759.5},\n",
       "  {'score': 388723.5},\n",
       "  {'score': 413159.5},\n",
       "  {'score': 364535.5},\n",
       "  {'score': 560251.5},\n",
       "  {'score': 1230271.5},\n",
       "  {'score': 712063.5},\n",
       "  {'score': 379255.5},\n",
       "  {'score': 389247.5},\n",
       "  {'score': 282979.5},\n",
       "  {'score': 843111.5},\n",
       "  {'score': 397799.5},\n",
       "  {'score': 356475.5},\n",
       "  {'score': 687799.5},\n",
       "  {'score': 357963.5},\n",
       "  {'score': 564383.5},\n",
       "  {'score': 365183.5},\n",
       "  {'score': 407147.5},\n",
       "  {'score': 627127.5},\n",
       "  {'score': 195087.5},\n",
       "  {'score': 599179.5},\n",
       "  {'score': 297759.5},\n",
       "  {'score': 471051.5},\n",
       "  {'score': 672651.5},\n",
       "  {'score': 912679.5},\n",
       "  {'score': 498279.5},\n",
       "  {'score': 1411899.5},\n",
       "  {'score': 459315.5},\n",
       "  {'score': 469355.5},\n",
       "  {'score': 909419.5},\n",
       "  {'score': 859091.5},\n",
       "  {'score': 403979.5},\n",
       "  {'score': 299223.5},\n",
       "  {'score': 272611.5},\n",
       "  {'score': 503791.5},\n",
       "  {'score': 162823.5},\n",
       "  {'score': 413639.5},\n",
       "  {'score': 385923.5},\n",
       "  {'score': 465355.5},\n",
       "  {'score': 748419.5},\n",
       "  {'score': 589763.5},\n",
       "  {'score': 759975.5},\n",
       "  {'score': 527879.5},\n",
       "  {'score': 753207.5},\n",
       "  {'score': 533619.5},\n",
       "  {'score': 970435.5},\n",
       "  {'score': 313271.5},\n",
       "  {'score': 390887.5},\n",
       "  {'score': 761827.5},\n",
       "  {'score': 120503.5},\n",
       "  {'score': 989731.5},\n",
       "  {'score': 416379.5},\n",
       "  {'score': 345255.5},\n",
       "  {'score': 242983.5},\n",
       "  {'score': 473419.5},\n",
       "  {'score': 872091.5},\n",
       "  {'score': 348367.5},\n",
       "  {'score': 314983.5},\n",
       "  {'score': 507231.5},\n",
       "  {'score': 845959.5},\n",
       "  {'score': 485315.5},\n",
       "  {'score': 952323.5},\n",
       "  {'score': 232595.5},\n",
       "  {'score': 445663.5},\n",
       "  {'score': 1002583.5},\n",
       "  {'score': 260535.5},\n",
       "  {'score': 685359.5},\n",
       "  {'score': 572619.5},\n",
       "  {'score': 570803.5},\n",
       "  {'score': 663899.5},\n",
       "  {'score': 932491.5},\n",
       "  {'score': 1169915.5},\n",
       "  {'score': 1613687.5},\n",
       "  {'score': 668491.5},\n",
       "  {'score': 478495.5},\n",
       "  {'score': 604775.5},\n",
       "  {'score': 551267.5},\n",
       "  {'score': 865319.5},\n",
       "  {'score': 1149367.5},\n",
       "  {'score': 305595.5},\n",
       "  {'score': 868711.5},\n",
       "  {'score': 548863.5},\n",
       "  {'score': 406843.5},\n",
       "  {'score': 192947.5},\n",
       "  {'score': 466731.5},\n",
       "  {'score': 380435.5},\n",
       "  {'score': 1486575.5},\n",
       "  {'score': 436919.5},\n",
       "  {'score': 672687.5},\n",
       "  {'score': 574387.5},\n",
       "  {'score': 1570951.5},\n",
       "  {'score': 415851.5},\n",
       "  {'score': 605875.5},\n",
       "  {'score': 827851.5},\n",
       "  {'score': 433711.5},\n",
       "  {'score': 582847.5},\n",
       "  {'score': 236607.5},\n",
       "  {'score': 713955.5},\n",
       "  {'score': 535903.5},\n",
       "  {'score': 1375051.5},\n",
       "  {'score': 532983.5},\n",
       "  {'score': 489887.5},\n",
       "  {'score': 307691.5},\n",
       "  {'score': 726143.5},\n",
       "  {'score': 389075.5},\n",
       "  {'score': 471275.5},\n",
       "  {'score': 611727.5},\n",
       "  {'score': 856667.5},\n",
       "  {'score': 38743.5},\n",
       "  {'score': 559935.5},\n",
       "  {'score': 458439.5},\n",
       "  {'score': 980147.5},\n",
       "  {'score': 386423.5},\n",
       "  {'score': 514199.5},\n",
       "  {'score': 559867.5},\n",
       "  {'score': 742159.5},\n",
       "  {'score': 209643.5},\n",
       "  {'score': 339215.5},\n",
       "  {'score': 431975.5},\n",
       "  {'score': 880295.5},\n",
       "  {'score': 392003.5},\n",
       "  {'score': 270699.5},\n",
       "  {'score': 95651.5},\n",
       "  {'score': 486823.5},\n",
       "  {'score': 271171.5},\n",
       "  {'score': 188027.5},\n",
       "  {'score': 675607.5},\n",
       "  {'score': 334271.5},\n",
       "  {'score': 425811.5},\n",
       "  {'score': 175435.5},\n",
       "  {'score': 594807.5},\n",
       "  {'score': 340691.5},\n",
       "  {'score': 536807.5},\n",
       "  {'score': 101211.5},\n",
       "  {'score': 171551.5},\n",
       "  {'score': 590947.5},\n",
       "  {'score': 628491.5},\n",
       "  {'score': 272311.5},\n",
       "  {'score': 833403.5},\n",
       "  {'score': 351783.5},\n",
       "  {'score': 144751.5},\n",
       "  {'score': 430587.5},\n",
       "  {'score': 758467.5},\n",
       "  {'score': 340671.5},\n",
       "  {'score': 609799.5},\n",
       "  {'score': 432063.5},\n",
       "  {'score': 926819.5},\n",
       "  {'score': 528899.5},\n",
       "  {'score': 420167.5},\n",
       "  {'score': 368611.5},\n",
       "  {'score': 204847.5},\n",
       "  {'score': 664775.5},\n",
       "  {'score': 451367.5},\n",
       "  {'score': 819183.5},\n",
       "  {'score': 282659.5},\n",
       "  {'score': 380831.5},\n",
       "  {'score': 384223.5},\n",
       "  {'score': 1866511.5},\n",
       "  {'score': 718303.5},\n",
       "  {'score': 427283.5},\n",
       "  {'score': 508075.5},\n",
       "  {'score': 402471.5},\n",
       "  {'score': 383579.5},\n",
       "  {'score': 426271.5},\n",
       "  {'score': 460659.5},\n",
       "  {'score': 172883.5},\n",
       "  {'score': 321327.5},\n",
       "  {'score': 311579.5},\n",
       "  {'score': 1085579.5},\n",
       "  {'score': 327955.5},\n",
       "  {'score': 880167.5},\n",
       "  {'score': 372339.5},\n",
       "  {'score': 520859.5},\n",
       "  {'score': 1535751.5},\n",
       "  {'score': 38643.5},\n",
       "  {'score': 356155.5},\n",
       "  {'score': 200431.5},\n",
       "  {'score': 265443.5},\n",
       "  {'score': 500363.5},\n",
       "  {'score': 372535.5},\n",
       "  {'score': 218843.5},\n",
       "  {'score': 350979.5},\n",
       "  {'score': 171199.5},\n",
       "  {'score': 1125143.5},\n",
       "  {'score': 1138323.5},\n",
       "  {'score': 717267.5},\n",
       "  {'score': 274911.5},\n",
       "  {'score': 273559.5},\n",
       "  {'score': 419171.5},\n",
       "  {'score': 533339.5},\n",
       "  {'score': 670215.5},\n",
       "  {'score': 917055.5},\n",
       "  {'score': 202379.5},\n",
       "  {'score': 563583.5},\n",
       "  {'score': 560115.5},\n",
       "  {'score': 383635.5},\n",
       "  {'score': 335171.5},\n",
       "  {'score': 541851.5},\n",
       "  {'score': 276399.5},\n",
       "  {'score': 1093967.5},\n",
       "  {'score': 161307.5},\n",
       "  {'score': 278187.5},\n",
       "  {'score': 1074179.5},\n",
       "  {'score': 594923.5},\n",
       "  {'score': 570231.5},\n",
       "  {'score': 342555.5},\n",
       "  {'score': 354859.5},\n",
       "  {'score': 594503.5},\n",
       "  {'score': 247595.5},\n",
       "  {'score': 714511.5},\n",
       "  {'score': 359339.5},\n",
       "  {'score': 577375.5},\n",
       "  {'score': 161623.5},\n",
       "  {'score': 974859.5},\n",
       "  {'score': 733191.5},\n",
       "  {'score': 531211.5},\n",
       "  {'score': 536455.5},\n",
       "  {'score': 977459.5},\n",
       "  {'score': 728835.5},\n",
       "  {'score': 459079.5},\n",
       "  {'score': 516883.5},\n",
       "  {'score': 349467.5},\n",
       "  {'score': 221915.5},\n",
       "  {'score': 732667.5},\n",
       "  {'score': 388623.5},\n",
       "  {'score': 304367.5},\n",
       "  {'score': 481271.5},\n",
       "  {'score': 487495.5},\n",
       "  {'score': 527379.5},\n",
       "  {'score': 613643.5},\n",
       "  {'score': 457967.5},\n",
       "  {'score': 618199.5},\n",
       "  {'score': 381395.5},\n",
       "  {'score': 691611.5},\n",
       "  {'score': 538883.5},\n",
       "  {'score': 701799.5},\n",
       "  {'score': 808915.5},\n",
       "  {'score': 963963.5},\n",
       "  {'score': 562935.5},\n",
       "  {'score': 529223.5},\n",
       "  {'score': 268247.5},\n",
       "  {'score': 619759.5},\n",
       "  {'score': 828075.5},\n",
       "  {'score': 516767.5},\n",
       "  {'score': 229483.5},\n",
       "  {'score': 172519.5},\n",
       "  {'score': 568879.5},\n",
       "  {'score': 533931.5},\n",
       "  {'score': 809799.5},\n",
       "  {'score': 225259.5},\n",
       "  {'score': 584155.5},\n",
       "  {'score': 633099.5},\n",
       "  {'score': 363067.5},\n",
       "  {'score': 464331.5},\n",
       "  {'score': 123019.5},\n",
       "  {'score': 199663.5},\n",
       "  {'score': 435823.5},\n",
       "  {'score': 447171.5},\n",
       "  {'score': 281039.5},\n",
       "  {'score': 503439.5},\n",
       "  {'score': 272275.5},\n",
       "  {'score': 451983.5},\n",
       "  {'score': 861491.5},\n",
       "  {'score': 112395.5},\n",
       "  {'score': 596407.5},\n",
       "  {'score': 301123.5},\n",
       "  {'score': 563947.5},\n",
       "  {'score': 675311.5},\n",
       "  {'score': 1094787.5},\n",
       "  {'score': 451863.5},\n",
       "  {'score': 202915.5},\n",
       "  {'score': 258379.5},\n",
       "  {'score': 153663.5},\n",
       "  {'score': 712139.5},\n",
       "  {'score': 599203.5},\n",
       "  {'score': 249251.5},\n",
       "  {'score': 551251.5},\n",
       "  {'score': 500759.5},\n",
       "  {'score': 387195.5},\n",
       "  {'score': 745415.5},\n",
       "  {'score': 1237443.5},\n",
       "  {'score': 239939.5},\n",
       "  {'score': 493455.5},\n",
       "  {'score': 112627.5},\n",
       "  {'score': 464479.5},\n",
       "  {'score': 480167.5},\n",
       "  {'score': 632067.5},\n",
       "  {'score': 596863.5},\n",
       "  {'score': 406219.5},\n",
       "  {'score': 989979.5},\n",
       "  {'score': 256007.5},\n",
       "  {'score': 596031.5},\n",
       "  {'score': 656415.5},\n",
       "  {'score': 262359.5},\n",
       "  {'score': 529027.5},\n",
       "  {'score': 577667.5},\n",
       "  {'score': 266387.5},\n",
       "  {'score': 879499.5},\n",
       "  {'score': 434675.5},\n",
       "  {'score': 514431.5},\n",
       "  {'score': 918003.5},\n",
       "  {'score': 726439.5},\n",
       "  {'score': 489075.5},\n",
       "  {'score': 1673979.5},\n",
       "  {'score': 471179.5},\n",
       "  {'score': 974511.5},\n",
       "  {'score': 656367.5},\n",
       "  {'score': 312247.5},\n",
       "  {'score': 630039.5},\n",
       "  {'score': 773683.5},\n",
       "  {'score': 135579.5},\n",
       "  {'score': 532043.5},\n",
       "  {'score': 162647.5},\n",
       "  {'score': 477651.5},\n",
       "  {'score': 1246863.5},\n",
       "  {'score': 349487.5},\n",
       "  {'score': 229315.5},\n",
       "  {'score': 729435.5},\n",
       "  {'score': 440999.5},\n",
       "  {'score': 420351.5},\n",
       "  {'score': 380231.5},\n",
       "  {'score': 359839.5},\n",
       "  {'score': 454627.5},\n",
       "  {'score': 176007.5},\n",
       "  {'score': 287911.5},\n",
       "  {'score': 448255.5},\n",
       "  {'score': 810083.5},\n",
       "  {'score': 1275095.5},\n",
       "  {'score': 574651.5},\n",
       "  {'score': 936719.5},\n",
       "  {'score': 1034791.5},\n",
       "  {'score': 338391.5},\n",
       "  {'score': 1264775.5},\n",
       "  {'score': 257827.5},\n",
       "  {'score': 647199.5},\n",
       "  {'score': 121183.5},\n",
       "  {'score': 555991.5},\n",
       "  {'score': 392527.5},\n",
       "  {'score': 492227.5},\n",
       "  {'score': 1438839.5},\n",
       "  {'score': 104027.5},\n",
       "  {'score': 406815.5},\n",
       "  {'score': 794935.5},\n",
       "  {'score': 428835.5},\n",
       "  {'score': 1137435.5},\n",
       "  {'score': 370491.5},\n",
       "  {'score': 50347.5},\n",
       "  {'score': 424787.5},\n",
       "  {'score': 307179.5},\n",
       "  {'score': 763111.5},\n",
       "  {'score': 937859.5},\n",
       "  {'score': 385991.5},\n",
       "  {'score': 303187.5},\n",
       "  {'score': 614423.5},\n",
       "  {'score': 380291.5},\n",
       "  {'score': 314939.5},\n",
       "  {'score': 472799.5},\n",
       "  {'score': 686207.5},\n",
       "  {'score': 18675.5},\n",
       "  {'score': 181331.5},\n",
       "  {'score': 343011.5},\n",
       "  {'score': 530835.5},\n",
       "  {'score': 804823.5},\n",
       "  {'score': 197631.5},\n",
       "  {'score': 877011.5},\n",
       "  {'score': 682835.5},\n",
       "  {'score': 428243.5},\n",
       "  {'score': 730747.5},\n",
       "  {'score': 460335.5},\n",
       "  {'score': 1097063.5},\n",
       "  {'score': 482295.5},\n",
       "  {'score': 86059.5},\n",
       "  {'score': 384299.5},\n",
       "  {'score': 470991.5},\n",
       "  {'score': 503279.5},\n",
       "  {'score': 468211.5},\n",
       "  {'score': 854891.5},\n",
       "  {'score': 551271.5},\n",
       "  {'score': 679743.5},\n",
       "  {'score': 510375.5},\n",
       "  {'score': 597343.5},\n",
       "  {'score': 479779.5},\n",
       "  {'score': 233323.5},\n",
       "  {'score': 111767.5},\n",
       "  {'score': 174927.5},\n",
       "  {'score': 227279.5},\n",
       "  {'score': 483027.5},\n",
       "  {'score': 275843.5},\n",
       "  {'score': 736403.5},\n",
       "  {'score': 435359.5},\n",
       "  {'score': 588019.5},\n",
       "  {'score': 1916687.5},\n",
       "  {'score': 537115.5},\n",
       "  {'score': 642383.5},\n",
       "  {'score': 874931.5},\n",
       "  {'score': 662975.5},\n",
       "  {'score': 315947.5},\n",
       "  {'score': 669299.5},\n",
       "  {'score': 675151.5},\n",
       "  {'score': 363339.5},\n",
       "  {'score': 638383.5},\n",
       "  {'score': 167751.5},\n",
       "  {'score': 223043.5},\n",
       "  {'score': 510263.5},\n",
       "  {'score': 504071.5},\n",
       "  {'score': 880275.5},\n",
       "  {'score': 708975.5},\n",
       "  {'score': 476399.5},\n",
       "  {'score': 186231.5},\n",
       "  {'score': 315771.5},\n",
       "  {'score': 525983.5},\n",
       "  {'score': 184311.5},\n",
       "  {'score': 639871.5},\n",
       "  {'score': 347775.5},\n",
       "  {'score': 476895.5},\n",
       "  {'score': 470779.5},\n",
       "  {'score': 384823.5},\n",
       "  {'score': 507899.5},\n",
       "  {'score': 329447.5},\n",
       "  {'score': 1233779.5},\n",
       "  {'score': 474403.5},\n",
       "  {'score': 615423.5},\n",
       "  {'score': 235591.5},\n",
       "  {'score': 734703.5},\n",
       "  {'score': 489679.5},\n",
       "  {'score': 612511.5},\n",
       "  {'score': 733267.5},\n",
       "  {'score': 280035.5},\n",
       "  {'score': 262423.5},\n",
       "  {'score': 513003.5},\n",
       "  {'score': 298551.5},\n",
       "  {'score': 627539.5},\n",
       "  {'score': 559563.5},\n",
       "  {'score': 693107.5},\n",
       "  {'score': 287351.5},\n",
       "  {'score': 329639.5},\n",
       "  {'score': 450299.5},\n",
       "  {'score': 497959.5},\n",
       "  {'score': 474027.5},\n",
       "  {'score': 196335.5},\n",
       "  {'score': 1563923.5},\n",
       "  {'score': 624451.5},\n",
       "  {'score': 798887.5},\n",
       "  {'score': 777051.5},\n",
       "  {'score': 648311.5},\n",
       "  {'score': 608011.5},\n",
       "  {'score': 1035807.5},\n",
       "  {'score': 463979.5},\n",
       "  {'score': 496071.5},\n",
       "  {'score': 360691.5},\n",
       "  {'score': 941579.5},\n",
       "  {'score': 463355.5},\n",
       "  {'score': 560111.5},\n",
       "  {'score': 533687.5},\n",
       "  {'score': 733635.5},\n",
       "  {'score': 128459.5},\n",
       "  {'score': 735499.5},\n",
       "  {'score': 468251.5},\n",
       "  {'score': 398135.5},\n",
       "  {'score': 427675.5},\n",
       "  {'score': 401659.5},\n",
       "  {'score': 219903.5},\n",
       "  {'score': 293139.5},\n",
       "  {'score': 267027.5},\n",
       "  {'score': 1159647.5},\n",
       "  {'score': 144159.5},\n",
       "  {'score': 360215.5},\n",
       "  {'score': 525999.5},\n",
       "  {'score': 384007.5},\n",
       "  {'score': 841719.5},\n",
       "  {'score': 325399.5},\n",
       "  {'score': 91927.5},\n",
       "  {'score': 529183.5},\n",
       "  {'score': 150307.5},\n",
       "  {'score': 371143.5},\n",
       "  {'score': 540251.5},\n",
       "  {'score': 588415.5},\n",
       "  {'score': 1239323.5},\n",
       "  {'score': 477899.5},\n",
       "  {'score': 143323.5},\n",
       "  {'score': 404815.5},\n",
       "  {'score': 1055007.5},\n",
       "  {'score': 252975.5},\n",
       "  {'score': 954203.5},\n",
       "  {'score': 439655.5},\n",
       "  {'score': 95491.5},\n",
       "  {'score': 286827.5},\n",
       "  {'score': 635487.5},\n",
       "  {'score': 226575.5},\n",
       "  {'score': 1156231.5},\n",
       "  {'score': 1913187.5},\n",
       "  {'score': 216035.5},\n",
       "  {'score': 502103.5},\n",
       "  {'score': 972071.5},\n",
       "  {'score': 401679.5},\n",
       "  {'score': 651443.5},\n",
       "  {'score': 935827.5},\n",
       "  {'score': 573959.5},\n",
       "  {'score': 498967.5},\n",
       "  {'score': 343163.5},\n",
       "  {'score': 111023.5},\n",
       "  {'score': 862391.5},\n",
       "  {'score': 439823.5},\n",
       "  {'score': 392531.5},\n",
       "  {'score': 387551.5},\n",
       "  {'score': 631787.5},\n",
       "  {'score': 257223.5},\n",
       "  {'score': 359363.5},\n",
       "  {'score': 757159.5},\n",
       "  {'score': 697911.5},\n",
       "  {'score': 497923.5},\n",
       "  {'score': 164831.5},\n",
       "  {'score': 424015.5},\n",
       "  {'score': 778367.5},\n",
       "  {'score': 591747.5},\n",
       "  {'score': 477803.5},\n",
       "  {'score': 1002443.5},\n",
       "  {'score': 245047.5},\n",
       "  {'score': 641443.5},\n",
       "  {'score': 1095575.5},\n",
       "  {'score': 492335.5},\n",
       "  {'score': 466659.5},\n",
       "  {'score': 370467.5},\n",
       "  {'score': 461055.5},\n",
       "  {'score': 414147.5},\n",
       "  {'score': 490371.5},\n",
       "  {'score': 899931.5},\n",
       "  {'score': 450275.5},\n",
       "  {'score': 202651.5},\n",
       "  {'score': 165443.5},\n",
       "  {'score': 209731.5},\n",
       "  {'score': 834907.5},\n",
       "  {'score': 1023291.5},\n",
       "  {'score': 413703.5},\n",
       "  {'score': 764847.5},\n",
       "  {'score': 666255.5},\n",
       "  {'score': 419467.5},\n",
       "  {'score': 955679.5},\n",
       "  {'score': 541787.5},\n",
       "  {'score': 224695.5},\n",
       "  {'score': 253651.5},\n",
       "  {'score': 360459.5},\n",
       "  {'score': 752127.5},\n",
       "  {'score': 582631.5},\n",
       "  {'score': 1517011.5},\n",
       "  {'score': 145631.5},\n",
       "  {'score': 640447.5},\n",
       "  {'score': 1279251.5},\n",
       "  {'score': 514795.5},\n",
       "  {'score': 484119.5},\n",
       "  {'score': 629059.5},\n",
       "  {'score': 388819.5},\n",
       "  {'score': 382603.5},\n",
       "  {'score': 486919.5},\n",
       "  {'score': 493619.5},\n",
       "  {'score': 486179.5},\n",
       "  {'score': 538495.5},\n",
       "  {'score': 630495.5},\n",
       "  {'score': 335847.5},\n",
       "  {'score': 390555.5},\n",
       "  {'score': 533779.5},\n",
       "  {'score': 633727.5},\n",
       "  {'score': 611099.5},\n",
       "  {'score': 614823.5},\n",
       "  {'score': 123631.5},\n",
       "  {'score': 563243.5},\n",
       "  {'score': 1220019.5},\n",
       "  {'score': 372707.5},\n",
       "  {'score': 597847.5},\n",
       "  {'score': 615287.5},\n",
       "  {'score': 766259.5},\n",
       "  {'score': 292911.5},\n",
       "  {'score': 344807.5},\n",
       "  {'score': 210831.5},\n",
       "  {'score': 405831.5},\n",
       "  {'score': 425699.5},\n",
       "  {'score': 1173063.5},\n",
       "  {'score': 668603.5},\n",
       "  {'score': 305775.5},\n",
       "  {'score': 295651.5},\n",
       "  {'score': 545875.5},\n",
       "  {'score': 593455.5},\n",
       "  {'score': 1083419.5},\n",
       "  {'score': 414591.5},\n",
       "  {'score': 131115.5},\n",
       "  {'score': 442207.5},\n",
       "  {'score': 1104083.5},\n",
       "  {'score': 413975.5},\n",
       "  {'score': 337207.5},\n",
       "  {'score': 305775.5},\n",
       "  {'score': 676175.5},\n",
       "  {'score': 324043.5},\n",
       "  {'score': 843135.5},\n",
       "  {'score': 261675.5},\n",
       "  {'score': 235075.5},\n",
       "  {'score': 608999.5},\n",
       "  {'score': 133259.5},\n",
       "  {'score': 468131.5},\n",
       "  {'score': 1465627.5},\n",
       "  {'score': 941871.5},\n",
       "  {'score': 595515.5},\n",
       "  {'score': 252511.5},\n",
       "  {'score': 404343.5},\n",
       "  {'score': 95331.5},\n",
       "  {'score': 218279.5},\n",
       "  {'score': 767891.5},\n",
       "  {'score': 441115.5},\n",
       "  {'score': 290703.5},\n",
       "  {'score': 476323.5},\n",
       "  {'score': 434435.5},\n",
       "  {'score': 1355199.5},\n",
       "  {'score': 359891.5},\n",
       "  {'score': 681987.5},\n",
       "  {'score': 452531.5},\n",
       "  {'score': 964875.5},\n",
       "  {'score': 638383.5},\n",
       "  {'score': 107251.5},\n",
       "  {'score': 1000963.5},\n",
       "  {'score': 421347.5},\n",
       "  {'score': 210371.5},\n",
       "  {'score': 271463.5},\n",
       "  {'score': 87259.5},\n",
       "  {'score': 334399.5},\n",
       "  {'score': 180279.5},\n",
       "  {'score': 802115.5},\n",
       "  {'score': 457187.5},\n",
       "  {'score': 896535.5},\n",
       "  {'score': 307055.5},\n",
       "  {'score': 530583.5},\n",
       "  {'score': 501103.5},\n",
       "  {'score': 427103.5},\n",
       "  {'score': 141719.5},\n",
       "  {'score': 262299.5},\n",
       "  {'score': 747171.5},\n",
       "  {'score': 425419.5},\n",
       "  {'score': 603087.5},\n",
       "  {'score': 424339.5},\n",
       "  {'score': 864603.5},\n",
       "  {'score': 710027.5},\n",
       "  {'score': 169035.5},\n",
       "  {'score': 973139.5},\n",
       "  {'score': 792963.5},\n",
       "  {'score': 337955.5},\n",
       "  {'score': 419259.5},\n",
       "  {'score': 426955.5},\n",
       "  {'score': 420723.5},\n",
       "  {'score': 745515.5},\n",
       "  {'score': 393203.5},\n",
       "  {'score': 630475.5},\n",
       "  {'score': 262367.5},\n",
       "  {'score': 500907.5},\n",
       "  {'score': 351835.5},\n",
       "  {'score': 574775.5},\n",
       "  {'score': 179527.5},\n",
       "  {'score': 307463.5},\n",
       "  {'score': 468399.5},\n",
       "  {'score': 799583.5},\n",
       "  {'score': 930963.5},\n",
       "  {'score': 236463.5},\n",
       "  {'score': 410927.5},\n",
       "  {'score': 789519.5},\n",
       "  {'score': 235023.5},\n",
       "  {'score': 200699.5},\n",
       "  {'score': 655539.5},\n",
       "  {'score': 850299.5},\n",
       "  {'score': 606695.5},\n",
       "  {'score': 643555.5},\n",
       "  {'score': 416771.5},\n",
       "  {'score': 560907.5},\n",
       "  {'score': 440387.5},\n",
       "  {'score': 407347.5},\n",
       "  {'score': 311731.5},\n",
       "  {'score': 303267.5},\n",
       "  {'score': 400951.5},\n",
       "  {'score': 746627.5},\n",
       "  {'score': 416759.5},\n",
       "  {'score': 760243.5},\n",
       "  {'score': 415831.5},\n",
       "  {'score': 897623.5},\n",
       "  {'score': 222623.5},\n",
       "  {'score': 348099.5},\n",
       "  {'score': 880023.5},\n",
       "  {'score': 184127.5},\n",
       "  {'score': 545067.5},\n",
       "  {'score': 269199.5},\n",
       "  {'score': 375787.5},\n",
       "  {'score': 150935.5},\n",
       "  {'score': 386303.5},\n",
       "  {'score': 830431.5},\n",
       "  {'score': 453343.5},\n",
       "  {'score': 615567.5},\n",
       "  {'score': 268895.5},\n",
       "  {'score': 209299.5},\n",
       "  {'score': 543935.5},\n",
       "  {'score': 902063.5},\n",
       "  {'score': 474639.5},\n",
       "  {'score': 224255.5},\n",
       "  {'score': 592335.5},\n",
       "  {'score': 534347.5},\n",
       "  {'score': 800431.5},\n",
       "  {'score': 707455.5},\n",
       "  {'score': 762843.5},\n",
       "  {'score': 802095.5},\n",
       "  {'score': 509119.5},\n",
       "  {'score': 573207.5},\n",
       "  {'score': 646343.5},\n",
       "  {'score': 925159.5},\n",
       "  {'score': 1473143.5},\n",
       "  {'score': 346695.5},\n",
       "  {'score': 359943.5},\n",
       "  {'score': 351467.5},\n",
       "  {'score': 427279.5},\n",
       "  {'score': 183083.5},\n",
       "  {'score': 373579.5},\n",
       "  {'score': 679331.5},\n",
       "  {'score': 249359.5},\n",
       "  {'score': 744683.5},\n",
       "  {'score': 569187.5},\n",
       "  {'score': 653239.5},\n",
       "  {'score': 275415.5},\n",
       "  {'score': 352311.5},\n",
       "  {'score': 162847.5},\n",
       "  {'score': 481927.5},\n",
       "  {'score': 283211.5},\n",
       "  {'score': 546755.5},\n",
       "  {'score': 211659.5},\n",
       "  {'score': 470675.5},\n",
       "  {'score': 266731.5},\n",
       "  {'score': 755735.5},\n",
       "  {'score': 278683.5},\n",
       "  {'score': 299979.5},\n",
       "  {'score': 539751.5},\n",
       "  {'score': 570387.5},\n",
       "  {'score': 1174063.5},\n",
       "  {'score': 1056703.5},\n",
       "  {'score': 281103.5},\n",
       "  {'score': 473931.5},\n",
       "  {'score': 360363.5},\n",
       "  {'score': 168475.5},\n",
       "  {'score': 387023.5},\n",
       "  {'score': 527251.5},\n",
       "  {'score': 824027.5},\n",
       "  {'score': 326491.5},\n",
       "  {'score': 868163.5},\n",
       "  {'score': 196931.5},\n",
       "  {'score': 617095.5},\n",
       "  {'score': 566295.5},\n",
       "  {'score': 557131.5},\n",
       "  {'score': 559995.5},\n",
       "  {'score': 847903.5},\n",
       "  {'score': 352583.5},\n",
       "  {'score': 514983.5},\n",
       "  {'score': 659391.5},\n",
       "  {'score': 210435.5},\n",
       "  {'score': 137723.5},\n",
       "  {'score': 694287.5},\n",
       "  {'score': 335295.5},\n",
       "  {'score': 658603.5},\n",
       "  {'score': 473083.5},\n",
       "  {'score': 344663.5},\n",
       "  {'score': 421415.5},\n",
       "  {'score': 332747.5},\n",
       "  {'score': 599103.5},\n",
       "  {'score': 420267.5},\n",
       "  {'score': 837367.5},\n",
       "  {'score': 336535.5},\n",
       "  {'score': 426447.5},\n",
       "  {'score': 458099.5},\n",
       "  {'score': 337155.5},\n",
       "  {'score': 230171.5},\n",
       "  {'score': 648203.5},\n",
       "  {'score': 945899.5},\n",
       "  {'score': 497883.5},\n",
       "  {'score': 233203.5},\n",
       "  {'score': 295923.5},\n",
       "  {'score': 990867.5},\n",
       "  {'score': 451371.5},\n",
       "  {'score': 267579.5},\n",
       "  {'score': 370659.5},\n",
       "  {'score': 441591.5},\n",
       "  {'score': 58579.5},\n",
       "  {'score': 413463.5},\n",
       "  {'score': 720779.5},\n",
       "  {'score': 1033651.5},\n",
       "  {'score': 238583.5},\n",
       "  {'score': 331331.5},\n",
       "  {'score': 381655.5},\n",
       "  {'score': 787355.5},\n",
       "  {'score': 773955.5},\n",
       "  {'score': 192779.5},\n",
       "  {'score': 542783.5},\n",
       "  {'score': 517499.5},\n",
       "  {'score': 254343.5},\n",
       "  {'score': 462275.5},\n",
       "  {'score': 1076867.5},\n",
       "  {'score': 985899.5},\n",
       "  {'score': 717963.5},\n",
       "  {'score': 902259.5},\n",
       "  {'score': 754527.5},\n",
       "  {'score': 268467.5},\n",
       "  {'score': 518195.5},\n",
       "  {'score': 772299.5},\n",
       "  {'score': 1002039.5},\n",
       "  {'score': 316771.5},\n",
       "  {'score': 1805043.5},\n",
       "  {'score': 1171199.5},\n",
       "  {'score': 283823.5},\n",
       "  {'score': 528235.5},\n",
       "  {'score': 276467.5},\n",
       "  {'score': 725519.5},\n",
       "  {'score': 483087.5},\n",
       "  {'score': 1276987.5},\n",
       "  {'score': 644527.5},\n",
       "  {'score': 559347.5},\n",
       "  {'score': 1506559.5},\n",
       "  {'score': 649071.5},\n",
       "  {'score': 419291.5},\n",
       "  {'score': 842447.5},\n",
       "  {'score': 402159.5},\n",
       "  {'score': 1775027.5},\n",
       "  {'score': 895931.5},\n",
       "  {'score': 315771.5},\n",
       "  {'score': 532255.5},\n",
       "  {'score': 683051.5},\n",
       "  {'score': 561203.5},\n",
       "  {'score': 595315.5},\n",
       "  {'score': 290999.5},\n",
       "  {'score': 450507.5},\n",
       "  {'score': 556155.5},\n",
       "  {'score': 857047.5},\n",
       "  {'score': 617567.5},\n",
       "  {'score': 773039.5},\n",
       "  {'score': 310723.5},\n",
       "  {'score': 927687.5},\n",
       "  {'score': 413443.5},\n",
       "  {'score': 222827.5},\n",
       "  {'score': 369475.5},\n",
       "  {'score': 1351155.5},\n",
       "  {'score': 497599.5},\n",
       "  {'score': 903111.5},\n",
       "  {'score': 466895.5},\n",
       "  {'score': 1600299.5},\n",
       "  {'score': 847283.5},\n",
       "  {'score': 546771.5},\n",
       "  {'score': 438095.5},\n",
       "  {'score': 258447.5},\n",
       "  {'score': 181419.5},\n",
       "  {'score': 603903.5},\n",
       "  {'score': 310039.5},\n",
       "  {'score': 766895.5},\n",
       "  {'score': 239767.5},\n",
       "  {'score': 554599.5},\n",
       "  {'score': 869199.5},\n",
       "  {'score': 668319.5},\n",
       "  {'score': 359831.5},\n",
       "  {'score': 521459.5},\n",
       "  {'score': 836019.5},\n",
       "  {'score': 822623.5},\n",
       "  {'score': 375559.5},\n",
       "  {'score': 461511.5},\n",
       "  {'score': 412483.5},\n",
       "  {'score': 992843.5},\n",
       "  {'score': 342527.5},\n",
       "  {'score': 355335.5},\n",
       "  {'score': 141939.5},\n",
       "  {'score': 979531.5},\n",
       "  {'score': 509527.5},\n",
       "  {'score': 922019.5},\n",
       "  {'score': 392775.5},\n",
       "  {'score': 772515.5},\n",
       "  {'score': 797895.5},\n",
       "  {'score': 241251.5},\n",
       "  {'score': 236703.5},\n",
       "  {'score': 319035.5},\n",
       "  {'score': 575855.5},\n",
       "  {'score': 428383.5},\n",
       "  {'score': 458283.5},\n",
       "  {'score': 357763.5},\n",
       "  {'score': 291771.5},\n",
       "  {'score': 291947.5},\n",
       "  {'score': 660735.5},\n",
       "  {'score': 487567.5},\n",
       "  {'score': 480351.5},\n",
       "  {'score': 825423.5},\n",
       "  {'score': 304751.5},\n",
       "  {'score': 191243.5},\n",
       "  {'score': 794975.5},\n",
       "  {'score': 202003.5},\n",
       "  {'score': 609083.5},\n",
       "  {'score': 143939.5},\n",
       "  {'score': 483535.5},\n",
       "  {'score': 1013687.5},\n",
       "  {'score': 381299.5},\n",
       "  {'score': 228647.5},\n",
       "  {'score': 280235.5},\n",
       "  {'score': 506547.5},\n",
       "  {'score': 327687.5},\n",
       "  {'score': 55147.5},\n",
       "  {'score': 1367591.5},\n",
       "  {'score': 539335.5},\n",
       "  {'score': 583771.5},\n",
       "  {'score': 342651.5},\n",
       "  {'score': 732663.5},\n",
       "  {'score': 470551.5},\n",
       "  {'score': 673439.5},\n",
       "  {'score': 571643.5},\n",
       "  {'score': 398207.5},\n",
       "  {'score': 479675.5},\n",
       "  {'score': 761047.5},\n",
       "  {'score': 426279.5},\n",
       "  {'score': 351991.5},\n",
       "  {'score': 1149903.5},\n",
       "  {'score': 432267.5},\n",
       "  {'score': 660871.5},\n",
       "  {'score': 670919.5},\n",
       "  {'score': 221315.5},\n",
       "  {'score': 734315.5},\n",
       "  {'score': 711283.5},\n",
       "  {'score': 623539.5},\n",
       "  {'score': 1072327.5},\n",
       "  {'score': 721431.5},\n",
       "  {'score': 1084167.5},\n",
       "  {'score': 566131.5},\n",
       "  {'score': 195135.5},\n",
       "  {'score': 773015.5},\n",
       "  {'score': 1103039.5},\n",
       "  {'score': 597211.5},\n",
       "  {'score': 1459723.5},\n",
       "  {'score': 241811.5},\n",
       "  {'score': 381579.5},\n",
       "  {'score': 827071.5},\n",
       "  {'score': 422511.5},\n",
       "  {'score': 308979.5},\n",
       "  {'score': 495699.5},\n",
       "  {'score': 648091.5},\n",
       "  {'score': 590851.5},\n",
       "  {'score': 632531.5},\n",
       "  {'score': 732059.5},\n",
       "  {'score': 649015.5},\n",
       "  {'score': 200491.5},\n",
       "  {'score': 729379.5},\n",
       "  {'score': 262287.5},\n",
       "  {'score': 1550183.5},\n",
       "  {'score': 464207.5},\n",
       "  {'score': 771107.5},\n",
       "  {'score': 341175.5},\n",
       "  {'score': 879287.5},\n",
       "  {'score': 200363.5},\n",
       "  {'score': 798903.5},\n",
       "  {'score': 394943.5},\n",
       "  {'score': 561479.5},\n",
       "  {'score': 400643.5},\n",
       "  {'score': 381419.5},\n",
       "  {'score': 602119.5},\n",
       "  {'score': 385523.5},\n",
       "  {'score': 1228383.5},\n",
       "  {'score': 1119891.5},\n",
       "  {'score': 580395.5},\n",
       "  {'score': 490763.5},\n",
       "  {'score': 346143.5},\n",
       "  {'score': 366363.5},\n",
       "  {'score': 183003.5},\n",
       "  {'score': 603483.5},\n",
       "  {'score': 424635.5},\n",
       "  {'score': 264415.5},\n",
       "  {'score': 650011.5},\n",
       "  {'score': 1584151.5},\n",
       "  {'score': 783923.5},\n",
       "  {'score': 42683.5},\n",
       "  {'score': 414175.5},\n",
       "  {'score': 326699.5},\n",
       "  {'score': 751187.5},\n",
       "  {'score': 201055.5},\n",
       "  {'score': 689315.5},\n",
       "  {'score': 775295.5},\n",
       "  {'score': 568575.5},\n",
       "  {'score': 969239.5},\n",
       "  {'score': 909383.5},\n",
       "  {'score': 579459.5},\n",
       "  {'score': 444795.5},\n",
       "  {'score': 203643.5},\n",
       "  {'score': 281283.5},\n",
       "  {'score': 1149091.5},\n",
       "  {'score': 767339.5},\n",
       "  {'score': 416843.5},\n",
       "  {'score': 448755.5},\n",
       "  {'score': 302927.5},\n",
       "  {'score': 681251.5},\n",
       "  {'score': 902875.5},\n",
       "  {'score': 359019.5},\n",
       "  {'score': 108583.5},\n",
       "  {'score': 803211.5},\n",
       "  {'score': 316167.5},\n",
       "  {'score': 222019.5},\n",
       "  {'score': 199083.5},\n",
       "  {'score': 207639.5},\n",
       "  ...]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = np.array([r['score'] for r in results['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 396383.5, 1486271.5,  541275.5, ...,  329699.5,  221863.5,\n",
       "        148915.5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6484,), (6484, 16))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes.shape, X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  123631.90222085132 \n",
      "MSE =  42970397575.36999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "mae = mean_absolute_error(y_teste, previsoes)\n",
    "mse = mean_squared_error(y_teste, previsoes)\n",
    "print('MAE = ', mae, '\\nMSE = ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: linear-learner-2024-06-16-15-21-23-090\n",
      "INFO:sagemaker:Deleting endpoint with name: linear-learner-2024-06-16-15-21-23-090\n"
     ]
    }
   ],
   "source": [
    "# Não executar se fizer o tuning dos parâmetros\n",
    "linear_regressor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
